"""
Feature Calculation Engine for Vulnerability Score Modeler.

Each feature is a daily calculation for an open position. All are optional
and can be enabled/disabled. Features fail loudly if required data is missing.

Available Features:
- days_held: Days since entry
- current_pl_pct: Current P/L as % of entry
- pl_momentum_7d: P/L change in last 7 days
- pl_momentum_14d: P/L change in last 14 days
- volatility_7d: 7-day rolling volatility
- distance_from_high: % below 52-week high
- distance_from_entry: % from entry price
- max_favorable_excursion: Best price since entry vs current
- entropy_7d: Price action noise (volatility w/o direction)
"""

from dataclasses import dataclass, field
from datetime import datetime, date
from typing import Dict, List, Optional, Any, Callable
from enum import Enum
import numpy as np
import pandas as pd


class FeatureImportance(Enum):
    """Feature importance levels."""
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"


class FeatureError(Exception):
    """
    Exception raised when a feature cannot be calculated.

    This is a LOUD failure - the calculation stops and the user is informed
    which data is missing and why the feature cannot be computed.
    """
    def __init__(self, feature_name: str, reason: str, missing_data: Optional[List[str]] = None):
        self.feature_name = feature_name
        self.reason = reason
        self.missing_data = missing_data or []
        message = f"Cannot calculate feature '{feature_name}': {reason}"
        if missing_data:
            message += f"\nMissing data: {', '.join(missing_data)}"
        super().__init__(message)


@dataclass
class FeatureWeight:
    """
    Configuration for a single feature's weight and parameters.

    Attributes:
        enabled: Whether this feature is included in scoring
        weight: Additive modifier to score (can be negative)
        decay_point: Days after which penalty increases (for time-based features)
        fast_decay_rate: Rate when trade is stagnant (low P/L)
        slow_decay_rate: Rate when trade is performing (high P/L)
        stagnation_threshold: P/L % below which trade is considered stagnant
        normalize_min: Minimum value for normalization (optional)
        normalize_max: Maximum value for normalization (optional)
    """
    enabled: bool = True
    weight: float = 1.0
    decay_point: int = 14
    fast_decay_rate: float = 5.0
    slow_decay_rate: float = 1.0
    stagnation_threshold: float = 2.0  # 2% P/L threshold
    normalize_min: Optional[float] = None
    normalize_max: Optional[float] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            'enabled': self.enabled,
            'weight': self.weight,
            'decay_point': self.decay_point,
            'fast_decay_rate': self.fast_decay_rate,
            'slow_decay_rate': self.slow_decay_rate,
            'stagnation_threshold': self.stagnation_threshold,
            'normalize_min': self.normalize_min,
            'normalize_max': self.normalize_max
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'FeatureWeight':
        """Create from dictionary."""
        return cls(
            enabled=data.get('enabled', True),
            weight=data.get('weight', 1.0),
            decay_point=data.get('decay_point', 14),
            fast_decay_rate=data.get('fast_decay_rate', 5.0),
            slow_decay_rate=data.get('slow_decay_rate', 1.0),
            stagnation_threshold=data.get('stagnation_threshold', 2.0),
            normalize_min=data.get('normalize_min'),
            normalize_max=data.get('normalize_max')
        )


@dataclass
class FeatureResult:
    """Result of a single feature calculation."""
    name: str
    raw_value: float
    normalized_value: float
    weighted_contribution: float
    is_calculable: bool
    error_message: Optional[str] = None


@dataclass
class FeatureDefinition:
    """Definition of a feature with metadata."""
    name: str
    description: str
    calculation_description: str
    units: str
    value_range: str
    importance: FeatureImportance
    required_columns: List[str]
    lookback_days: int = 0  # How many days of history needed

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for UI display."""
        return {
            'name': self.name,
            'description': self.description,
            'calculation': self.calculation_description,
            'units': self.units,
            'range': self.value_range,
            'importance': self.importance.value,
            'required_columns': self.required_columns,
            'lookback_days': self.lookback_days
        }


# Define all available features with their metadata
AVAILABLE_FEATURES: Dict[str, FeatureDefinition] = {
    'days_held': FeatureDefinition(
        name='days_held',
        description='Days since entry',
        calculation_description='(current_date - entry_date).days',
        units='Days',
        value_range='0 to N',
        importance=FeatureImportance.HIGH,
        required_columns=['date'],
        lookback_days=0
    ),
    'current_pl_pct': FeatureDefinition(
        name='current_pl_pct',
        description='Current P/L as % of entry',
        calculation_description='(current_price - entry_price) / entry_price * 100',
        units='%',
        value_range='-100 to +infinity',
        importance=FeatureImportance.HIGH,
        required_columns=['close'],
        lookback_days=0
    ),
    'pl_momentum_7d': FeatureDefinition(
        name='pl_momentum_7d',
        description='P/L change in last 7 days',
        calculation_description='current_pl_pct - pl_pct_7days_ago',
        units='%',
        value_range='-infinity to +infinity',
        importance=FeatureImportance.HIGH,
        required_columns=['close'],
        lookback_days=7
    ),
    'pl_momentum_14d': FeatureDefinition(
        name='pl_momentum_14d',
        description='P/L change in last 14 days',
        calculation_description='current_pl_pct - pl_pct_14days_ago',
        units='%',
        value_range='-infinity to +infinity',
        importance=FeatureImportance.MEDIUM,
        required_columns=['close'],
        lookback_days=14
    ),
    'volatility_7d': FeatureDefinition(
        name='volatility_7d',
        description='7-day rolling volatility',
        calculation_description='std(daily_returns[-7:])',
        units='%',
        value_range='0 to 100',
        importance=FeatureImportance.MEDIUM,
        required_columns=['close'],
        lookback_days=7
    ),
    'distance_from_high': FeatureDefinition(
        name='distance_from_high',
        description='% below 52-week high',
        calculation_description='(current_price - high_52w) / high_52w * 100',
        units='%',
        value_range='-100 to 0',
        importance=FeatureImportance.MEDIUM,
        required_columns=['close', 'high'],
        lookback_days=252  # 52 weeks of trading days
    ),
    'distance_from_entry': FeatureDefinition(
        name='distance_from_entry',
        description='% from entry price',
        calculation_description='(current_price - entry_price) / entry_price * 100',
        units='%',
        value_range='-100 to +infinity',
        importance=FeatureImportance.MEDIUM,
        required_columns=['close'],
        lookback_days=0
    ),
    'max_favorable_excursion': FeatureDefinition(
        name='max_favorable_excursion',
        description='Best price since entry vs current',
        calculation_description='(max_price - current_price) / max_price * 100',
        units='%',
        value_range='0 to 100',
        importance=FeatureImportance.LOW,
        required_columns=['close', 'high'],
        lookback_days=0  # Only needs data since entry
    ),
    'entropy_7d': FeatureDefinition(
        name='entropy_7d',
        description='Price action noise (volatility w/o direction)',
        calculation_description='std(close[-7:]) / mean(close[-7:])',
        units='%',
        value_range='0 to 100',
        importance=FeatureImportance.LOW,
        required_columns=['close'],
        lookback_days=7
    )
}


# Default feature weights based on spec
DEFAULT_FEATURE_WEIGHTS: Dict[str, FeatureWeight] = {
    'days_held': FeatureWeight(
        enabled=True,
        weight=-5.0,  # Negative = loses points per day
        decay_point=14,
        fast_decay_rate=5.0,
        slow_decay_rate=1.0
    ),
    'current_pl_pct': FeatureWeight(
        enabled=True,
        weight=1.0,
        stagnation_threshold=2.0
    ),
    'pl_momentum_7d': FeatureWeight(
        enabled=True,
        weight=3.0  # Recent momentum = high weight
    ),
    'pl_momentum_14d': FeatureWeight(
        enabled=False,
        weight=0.0
    ),
    'volatility_7d': FeatureWeight(
        enabled=True,
        weight=0.5
    ),
    'distance_from_high': FeatureWeight(
        enabled=False,
        weight=0.0
    ),
    'distance_from_entry': FeatureWeight(
        enabled=False,
        weight=0.0
    ),
    'max_favorable_excursion': FeatureWeight(
        enabled=False,
        weight=0.0
    ),
    'entropy_7d': FeatureWeight(
        enabled=False,
        weight=0.0
    )
}


class FeatureCalculator:
    """
    Calculates vulnerability score features for open positions.

    This calculator computes daily feature values for a trade using
    raw price data from CSV files. It validates that required data
    exists and fails loudly if data is missing.

    Usage:
        calculator = FeatureCalculator(feature_weights)
        result = calculator.calculate_feature('days_held', trade_context)
        all_results = calculator.calculate_all_features(trade_context)
    """

    def __init__(self, feature_weights: Optional[Dict[str, FeatureWeight]] = None):
        """
        Initialize the feature calculator.

        Args:
            feature_weights: Dictionary mapping feature names to FeatureWeight configs.
                           If None, uses DEFAULT_FEATURE_WEIGHTS.
        """
        self.feature_weights = feature_weights or DEFAULT_FEATURE_WEIGHTS.copy()
        self._validate_feature_weights()

    def _validate_feature_weights(self) -> None:
        """Validate that all feature weights reference valid features."""
        for feature_name in self.feature_weights.keys():
            if feature_name not in AVAILABLE_FEATURES:
                raise ValueError(
                    f"Unknown feature '{feature_name}'. "
                    f"Available features: {list(AVAILABLE_FEATURES.keys())}"
                )

    def get_enabled_features(self) -> List[str]:
        """Get list of enabled feature names."""
        return [
            name for name, weight in self.feature_weights.items()
            if weight.enabled
        ]

    def check_data_availability(
        self,
        price_data: pd.DataFrame,
        entry_date: datetime,
        current_date: datetime
    ) -> Dict[str, Dict[str, Any]]:
        """
        Check which features can be calculated with available data.

        This method checks data availability WITHOUT calculating features.
        Use this to warn users about missing data before running analysis.

        Args:
            price_data: DataFrame with price history (must have 'date', 'close', optionally 'high', 'low')
            entry_date: Trade entry date
            current_date: Current evaluation date

        Returns:
            Dictionary mapping feature name to availability info:
            {
                'feature_name': {
                    'available': bool,
                    'missing_columns': List[str],
                    'insufficient_history': bool,
                    'days_available': int,
                    'days_required': int
                }
            }
        """
        results = {}

        # Validate basic data structure
        if 'date' not in price_data.columns:
            raise FeatureError(
                'data_validation',
                "Price data must contain 'date' column",
                ['date']
            )

        available_columns = set(price_data.columns)

        # Calculate days of history available
        if len(price_data) > 0:
            data_start = pd.to_datetime(price_data['date'].min())
            data_end = pd.to_datetime(price_data['date'].max())

            # Filter to relevant date range
            mask = (price_data['date'] <= current_date) & (price_data['date'] >= entry_date)
            relevant_data = price_data[mask]
            days_of_data = len(relevant_data)
        else:
            days_of_data = 0

        for feature_name, definition in AVAILABLE_FEATURES.items():
            # Check required columns
            missing_columns = [
                col for col in definition.required_columns
                if col not in available_columns
            ]

            # Check history requirements
            days_required = definition.lookback_days
            insufficient_history = days_of_data < days_required if days_required > 0 else False

            results[feature_name] = {
                'available': len(missing_columns) == 0 and not insufficient_history,
                'missing_columns': missing_columns,
                'insufficient_history': insufficient_history,
                'days_available': days_of_data,
                'days_required': days_required
            }

        return results

    def calculate_feature(
        self,
        feature_name: str,
        entry_date: datetime,
        entry_price: float,
        current_date: datetime,
        current_price: float,
        price_data: pd.DataFrame,
        prices_since_entry: Optional[pd.DataFrame] = None
    ) -> FeatureResult:
        """
        Calculate a single feature value.

        Args:
            feature_name: Name of the feature to calculate
            entry_date: Trade entry date
            entry_price: Trade entry price
            current_date: Current evaluation date
            current_price: Current price
            price_data: Full price history DataFrame
            prices_since_entry: Subset of price_data from entry to current (optional, calculated if not provided)

        Returns:
            FeatureResult with raw value, normalized value, and weighted contribution

        Raises:
            FeatureError: If the feature cannot be calculated due to missing data
        """
        if feature_name not in AVAILABLE_FEATURES:
            raise FeatureError(feature_name, f"Unknown feature: {feature_name}")

        definition = AVAILABLE_FEATURES[feature_name]
        weight_config = self.feature_weights.get(feature_name, FeatureWeight(enabled=False))

        if not weight_config.enabled:
            return FeatureResult(
                name=feature_name,
                raw_value=0.0,
                normalized_value=0.0,
                weighted_contribution=0.0,
                is_calculable=True,
                error_message="Feature is disabled"
            )

        # Validate required columns
        missing_columns = [
            col for col in definition.required_columns
            if col not in price_data.columns
        ]
        if missing_columns:
            raise FeatureError(
                feature_name,
                f"Required columns not found in price data",
                missing_columns
            )

        # Get prices since entry if not provided
        if prices_since_entry is None:
            mask = (price_data['date'] >= entry_date) & (price_data['date'] <= current_date)
            prices_since_entry = price_data[mask].copy()

        # Calculate the raw feature value
        raw_value = self._calculate_raw_value(
            feature_name,
            entry_date,
            entry_price,
            current_date,
            current_price,
            price_data,
            prices_since_entry,
            weight_config
        )

        # Normalize the value (currently pass-through, can be customized)
        normalized_value = self._normalize_value(raw_value, weight_config)

        # Apply weight
        weighted_contribution = normalized_value * weight_config.weight

        return FeatureResult(
            name=feature_name,
            raw_value=raw_value,
            normalized_value=normalized_value,
            weighted_contribution=weighted_contribution,
            is_calculable=True
        )

    def _calculate_raw_value(
        self,
        feature_name: str,
        entry_date: datetime,
        entry_price: float,
        current_date: datetime,
        current_price: float,
        price_data: pd.DataFrame,
        prices_since_entry: pd.DataFrame,
        weight_config: FeatureWeight
    ) -> float:
        """Calculate the raw value for a specific feature."""

        if feature_name == 'days_held':
            return self._calc_days_held(entry_date, current_date)

        elif feature_name == 'current_pl_pct':
            return self._calc_current_pl_pct(entry_price, current_price)

        elif feature_name == 'pl_momentum_7d':
            return self._calc_pl_momentum(
                entry_price, current_price, prices_since_entry, lookback_days=7
            )

        elif feature_name == 'pl_momentum_14d':
            return self._calc_pl_momentum(
                entry_price, current_price, prices_since_entry, lookback_days=14
            )

        elif feature_name == 'volatility_7d':
            return self._calc_volatility(prices_since_entry, lookback_days=7)

        elif feature_name == 'distance_from_high':
            return self._calc_distance_from_high(
                current_price, current_date, price_data, lookback_days=252
            )

        elif feature_name == 'distance_from_entry':
            return self._calc_distance_from_entry(entry_price, current_price)

        elif feature_name == 'max_favorable_excursion':
            return self._calc_max_favorable_excursion(
                current_price, prices_since_entry
            )

        elif feature_name == 'entropy_7d':
            return self._calc_entropy(prices_since_entry, lookback_days=7)

        else:
            raise FeatureError(feature_name, f"No calculation implemented for feature")

    def _calc_days_held(self, entry_date: datetime, current_date: datetime) -> float:
        """Calculate days since entry."""
        # Handle both datetime and date objects
        if hasattr(entry_date, 'date'):
            entry = entry_date.date() if callable(getattr(entry_date, 'date', None)) else entry_date
        else:
            entry = entry_date

        if hasattr(current_date, 'date'):
            current = current_date.date() if callable(getattr(current_date, 'date', None)) else current_date
        else:
            current = current_date

        if isinstance(entry, datetime):
            entry = entry.date()
        if isinstance(current, datetime):
            current = current.date()

        return float((current - entry).days)

    def _calc_current_pl_pct(self, entry_price: float, current_price: float) -> float:
        """Calculate current P/L percentage."""
        if entry_price == 0:
            raise FeatureError('current_pl_pct', "Entry price cannot be zero")
        return ((current_price - entry_price) / entry_price) * 100

    def _calc_pl_momentum(
        self,
        entry_price: float,
        current_price: float,
        prices_since_entry: pd.DataFrame,
        lookback_days: int
    ) -> float:
        """Calculate P/L momentum over lookback period."""
        if len(prices_since_entry) < lookback_days:
            raise FeatureError(
                f'pl_momentum_{lookback_days}d',
                f"Insufficient price history for {lookback_days}-day momentum calculation",
                [f"Need at least {lookback_days} days of data, have {len(prices_since_entry)}"]
            )

        if entry_price == 0:
            raise FeatureError(f'pl_momentum_{lookback_days}d', "Entry price cannot be zero")

        # Current P/L %
        current_pl_pct = ((current_price - entry_price) / entry_price) * 100

        # P/L % from lookback_days ago
        price_lookback_ago = prices_since_entry['close'].iloc[-lookback_days]
        pl_pct_lookback = ((price_lookback_ago - entry_price) / entry_price) * 100

        return current_pl_pct - pl_pct_lookback

    def _calc_volatility(self, prices_since_entry: pd.DataFrame, lookback_days: int) -> float:
        """Calculate rolling volatility."""
        if len(prices_since_entry) < lookback_days:
            raise FeatureError(
                f'volatility_{lookback_days}d',
                f"Insufficient price history for {lookback_days}-day volatility calculation",
                [f"Need at least {lookback_days} days of data, have {len(prices_since_entry)}"]
            )

        # Calculate daily returns for the lookback period
        recent_closes = prices_since_entry['close'].tail(lookback_days)
        daily_returns = recent_closes.pct_change().dropna()

        if len(daily_returns) == 0:
            return 0.0

        # Return annualized volatility as percentage
        return float(daily_returns.std() * np.sqrt(252) * 100)

    def _calc_distance_from_high(
        self,
        current_price: float,
        current_date: datetime,
        price_data: pd.DataFrame,
        lookback_days: int
    ) -> float:
        """Calculate distance from 52-week high."""
        # Get data for lookback period
        mask = price_data['date'] <= current_date
        relevant_data = price_data[mask].tail(lookback_days)

        if len(relevant_data) < lookback_days:
            raise FeatureError(
                'distance_from_high',
                f"Insufficient price history for 52-week high calculation",
                [f"Need {lookback_days} days of data, have {len(relevant_data)}"]
            )

        if 'high' not in relevant_data.columns:
            raise FeatureError(
                'distance_from_high',
                "Price data missing 'high' column required for 52-week high calculation",
                ['high']
            )

        high_52w = relevant_data['high'].max()

        if high_52w == 0:
            return 0.0

        return ((current_price - high_52w) / high_52w) * 100

    def _calc_distance_from_entry(self, entry_price: float, current_price: float) -> float:
        """Calculate distance from entry price (same as current_pl_pct)."""
        if entry_price == 0:
            raise FeatureError('distance_from_entry', "Entry price cannot be zero")
        return ((current_price - entry_price) / entry_price) * 100

    def _calc_max_favorable_excursion(
        self,
        current_price: float,
        prices_since_entry: pd.DataFrame
    ) -> float:
        """Calculate max favorable excursion (drawdown from best price since entry)."""
        if len(prices_since_entry) == 0:
            return 0.0

        # Use high if available, otherwise close
        if 'high' in prices_since_entry.columns:
            max_price = prices_since_entry['high'].max()
        else:
            max_price = prices_since_entry['close'].max()

        if max_price == 0:
            return 0.0

        return ((max_price - current_price) / max_price) * 100

    def _calc_entropy(self, prices_since_entry: pd.DataFrame, lookback_days: int) -> float:
        """Calculate price entropy (coefficient of variation)."""
        if len(prices_since_entry) < lookback_days:
            raise FeatureError(
                f'entropy_{lookback_days}d',
                f"Insufficient price history for {lookback_days}-day entropy calculation",
                [f"Need at least {lookback_days} days of data, have {len(prices_since_entry)}"]
            )

        recent_closes = prices_since_entry['close'].tail(lookback_days)
        mean_price = recent_closes.mean()

        if mean_price == 0:
            return 0.0

        return float((recent_closes.std() / mean_price) * 100)

    def _normalize_value(self, raw_value: float, weight_config: FeatureWeight) -> float:
        """
        Normalize a raw feature value.

        Currently uses pass-through normalization. Can be extended to support
        min-max normalization or other schemes.
        """
        if weight_config.normalize_min is not None and weight_config.normalize_max is not None:
            # Min-max normalization to [0, 1] range
            range_val = weight_config.normalize_max - weight_config.normalize_min
            if range_val == 0:
                return 0.0
            normalized = (raw_value - weight_config.normalize_min) / range_val
            return max(0.0, min(1.0, normalized))

        # Pass-through (no normalization)
        return raw_value

    def calculate_all_features(
        self,
        entry_date: datetime,
        entry_price: float,
        current_date: datetime,
        current_price: float,
        price_data: pd.DataFrame
    ) -> Dict[str, FeatureResult]:
        """
        Calculate all enabled features for a trade on a given date.

        Args:
            entry_date: Trade entry date
            entry_price: Trade entry price
            current_date: Current evaluation date
            current_price: Current price
            price_data: Full price history DataFrame

        Returns:
            Dictionary mapping feature name to FeatureResult

        Raises:
            FeatureError: If any enabled feature cannot be calculated
        """
        results = {}

        # Pre-filter prices since entry for efficiency
        mask = (price_data['date'] >= entry_date) & (price_data['date'] <= current_date)
        prices_since_entry = price_data[mask].copy()

        for feature_name, weight_config in self.feature_weights.items():
            if not weight_config.enabled:
                results[feature_name] = FeatureResult(
                    name=feature_name,
                    raw_value=0.0,
                    normalized_value=0.0,
                    weighted_contribution=0.0,
                    is_calculable=True,
                    error_message="Feature is disabled"
                )
                continue

            # Calculate feature - will raise FeatureError if data missing
            results[feature_name] = self.calculate_feature(
                feature_name,
                entry_date,
                entry_price,
                current_date,
                current_price,
                price_data,
                prices_since_entry
            )

        return results

    def get_total_weighted_contribution(self, results: Dict[str, FeatureResult]) -> float:
        """
        Calculate total weighted contribution from all feature results.

        Args:
            results: Dictionary of FeatureResults from calculate_all_features()

        Returns:
            Sum of all weighted contributions
        """
        return sum(r.weighted_contribution for r in results.values() if r.is_calculable)
