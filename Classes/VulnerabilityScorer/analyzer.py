"""
P/L Impact Analysis and Reporting for Vulnerability Score Modeler.

This module analyzes the P/L impact of using vulnerability-based exits versus
natural strategy exits. It generates comprehensive reports with trade-by-trade
analysis and portfolio-level metrics.

Key Questions Answered:
- How much did I lose/gain from vulnerability-based exits?
- Which trades benefited vs. were hurt by the scoring function?
- What is the optimal parameter configuration?
"""

from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
import json
from pathlib import Path
import pandas as pd
import numpy as np

from .scoring import (
    VulnerabilityScoreParams,
    VulnerabilityScoringEngine,
    DailyVulnerabilityRecord
)
from .simulator import (
    SwapSimulator,
    SwapEvent,
    SimulationResult,
    SignalInjector
)
from .features import FeatureError


@dataclass
class TradeVulnerabilityAnalysis:
    """
    Complete vulnerability analysis for a single trade.

    Contains all metrics needed to understand how vulnerability scoring
    would have affected this specific trade.
    """
    trade_id: str
    symbol: str
    entry_date: datetime
    entry_price: float

    # Natural exit (from backtest)
    exit_date_natural: datetime
    exit_price_natural: float
    pl_natural_pct: float
    pl_natural_dollars: float

    # Vulnerability analysis
    first_vulnerable_date: Optional[datetime]
    first_vulnerable_score: float
    first_vulnerable_pl_pct: float
    days_before_vulnerability_exit: int

    # Counterfactual (if we had used vulnerability scoring)
    pl_if_exited_at_vulnerability_pct: float
    pl_if_exited_at_vulnerability_dollars: float
    pl_difference_pct: float
    pl_difference_dollars: float

    # Quality metrics
    was_loser: bool  # Natural exit was a loss
    would_have_been_swapped: bool
    benefit_category: str  # 'AVOIDED_LOSS', 'KILLED_WINNER', 'NEUTRAL', 'IMPROVED_EXIT'

    # Daily timeline (for charting)
    daily_timeline: List[DailyVulnerabilityRecord] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for export."""
        return {
            'trade_id': self.trade_id,
            'symbol': self.symbol,
            'entry_date': self.entry_date.strftime('%Y-%m-%d') if hasattr(self.entry_date, 'strftime') else str(self.entry_date),
            'entry_price': self.entry_price,
            'exit_date_natural': self.exit_date_natural.strftime('%Y-%m-%d') if hasattr(self.exit_date_natural, 'strftime') else str(self.exit_date_natural),
            'exit_price_natural': self.exit_price_natural,
            'pl_natural_pct': self.pl_natural_pct,
            'pl_natural_dollars': self.pl_natural_dollars,
            'first_vulnerable_date': self.first_vulnerable_date.strftime('%Y-%m-%d') if self.first_vulnerable_date and hasattr(self.first_vulnerable_date, 'strftime') else None,
            'first_vulnerable_score': self.first_vulnerable_score,
            'first_vulnerable_pl_pct': self.first_vulnerable_pl_pct,
            'days_before_vulnerability_exit': self.days_before_vulnerability_exit,
            'pl_if_exited_at_vulnerability_pct': self.pl_if_exited_at_vulnerability_pct,
            'pl_if_exited_at_vulnerability_dollars': self.pl_if_exited_at_vulnerability_dollars,
            'pl_difference_pct': self.pl_difference_pct,
            'pl_difference_dollars': self.pl_difference_dollars,
            'was_loser': self.was_loser,
            'would_have_been_swapped': self.would_have_been_swapped,
            'benefit_category': self.benefit_category
        }


@dataclass
class VulnerabilityAnalysisReport:
    """
    Complete analysis report for a backtest with vulnerability scoring.

    Contains portfolio-level metrics, trade-by-trade analysis, and
    all data needed for visualization and reporting.
    """
    symbol: str
    date_range: Tuple[datetime, datetime]
    parameter_set: VulnerabilityScoreParams

    # Trade-level analysis
    trades: List[TradeVulnerabilityAnalysis]

    # Summary statistics
    total_trades: int
    trades_affected_by_vulnerability: int

    # P/L Analysis
    total_pl_natural: float
    total_pl_if_vulnerability: float
    total_pl_difference: float
    total_pl_difference_pct: float

    # Trade Categorization
    benefited_count: int  # Trades where vulnerability score was better
    hurt_count: int  # Trades where vulnerability score was worse
    neutral_count: int  # Negligible difference

    # Quality Metrics
    false_positive_rate: float  # % of trades closed but would have recovered
    accuracy: float  # % of trades where vulnerability decision was good

    # Timing metrics
    avg_days_early_exit: float
    avg_pl_at_swap: float

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for export."""
        return {
            'symbol': self.symbol,
            'date_range': [
                self.date_range[0].strftime('%Y-%m-%d') if hasattr(self.date_range[0], 'strftime') else str(self.date_range[0]),
                self.date_range[1].strftime('%Y-%m-%d') if hasattr(self.date_range[1], 'strftime') else str(self.date_range[1])
            ],
            'parameter_set': self.parameter_set.to_dict(),
            'trades': [t.to_dict() for t in self.trades],
            'total_trades': self.total_trades,
            'trades_affected_by_vulnerability': self.trades_affected_by_vulnerability,
            'total_pl_natural': self.total_pl_natural,
            'total_pl_if_vulnerability': self.total_pl_if_vulnerability,
            'total_pl_difference': self.total_pl_difference,
            'total_pl_difference_pct': self.total_pl_difference_pct,
            'benefited_count': self.benefited_count,
            'hurt_count': self.hurt_count,
            'neutral_count': self.neutral_count,
            'false_positive_rate': self.false_positive_rate,
            'accuracy': self.accuracy,
            'avg_days_early_exit': self.avg_days_early_exit,
            'avg_pl_at_swap': self.avg_pl_at_swap
        }

    def to_json(self, filepath: Path) -> None:
        """Save report to JSON file."""
        with open(filepath, 'w') as f:
            json.dump(self.to_dict(), f, indent=2, default=str)

    def to_csv(self, filepath: Path) -> None:
        """Save trade analysis to CSV file."""
        trade_dicts = [t.to_dict() for t in self.trades]
        df = pd.DataFrame(trade_dicts)
        df.to_csv(filepath, index=False)

    def get_summary_text(self) -> str:
        """Get human-readable summary text."""
        lines = [
            f"Vulnerability Score Analysis Report",
            f"=" * 50,
            f"Symbol: {self.symbol}",
            f"Date Range: {self.date_range[0]} to {self.date_range[1]}",
            f"Parameters: {self.parameter_set.name}",
            f"",
            f"--- TRADE SUMMARY ---",
            f"Total Trades: {self.total_trades}",
            f"Trades Affected: {self.trades_affected_by_vulnerability} ({self.trades_affected_by_vulnerability/self.total_trades*100:.1f}%)" if self.total_trades > 0 else "Trades Affected: 0",
            f"",
            f"--- P/L IMPACT ---",
            f"Natural Total P/L: ${self.total_pl_natural:,.2f}",
            f"Vulnerability Total P/L: ${self.total_pl_if_vulnerability:,.2f}",
            f"Difference: ${self.total_pl_difference:,.2f} ({self.total_pl_difference_pct:+.2f}%)",
            f"",
            f"--- TRADE CATEGORIZATION ---",
            f"Benefited: {self.benefited_count}",
            f"Hurt: {self.hurt_count}",
            f"Neutral: {self.neutral_count}",
            f"",
            f"--- QUALITY METRICS ---",
            f"False Positive Rate: {self.false_positive_rate*100:.1f}%",
            f"Accuracy: {self.accuracy*100:.1f}%",
            f"",
            f"--- TIMING ---",
            f"Avg Days Early Exit: {self.avg_days_early_exit:.1f}",
            f"Avg P/L at Swap: {self.avg_pl_at_swap:.2f}%",
        ]
        return "\n".join(lines)

    def get_key_insight(self) -> str:
        """Generate a key insight based on the analysis."""
        if self.trades_affected_by_vulnerability == 0:
            return "No trades would have been affected by vulnerability scoring with current parameters."

        if self.total_pl_difference > 0:
            return f"Vulnerability scoring would have IMPROVED returns by ${self.total_pl_difference:,.2f}. " \
                   f"Consider enabling it with these parameters."

        if self.hurt_count > self.benefited_count:
            return f"Vulnerability scoring is too aggressive - closing {self.hurt_count} winners too early. " \
                   f"Consider increasing swap threshold or reducing decay rate."

        if self.false_positive_rate > 0.4:
            return f"High false positive rate ({self.false_positive_rate*100:.0f}%). " \
                   f"Many trades would be closed but would have recovered. Increase immunity period."

        return f"Vulnerability scoring shows mixed results. " \
               f"P/L difference: ${self.total_pl_difference:,.2f}."

    def get_recommendation(self) -> str:
        """Generate a recommendation based on the analysis."""
        if self.total_pl_difference > 0 and self.accuracy > 0.6:
            return "RECOMMEND: Enable vulnerability scoring with current parameters."

        if self.false_positive_rate > 0.5:
            return f"ADJUST: Increase immunity_days from {self.parameter_set.immunity_days} to {self.parameter_set.immunity_days + 5}"

        if self.hurt_count > self.benefited_count * 2:
            return f"ADJUST: Increase swap_threshold from {self.parameter_set.swap_threshold} to {min(90, self.parameter_set.swap_threshold + 20)}"

        if self.trades_affected_by_vulnerability < self.total_trades * 0.1:
            return f"ADJUST: Parameters are too conservative. Reduce immunity_days or increase weights."

        return "CONTINUE: Run additional simulations with different parameters to find optimal configuration."


class VulnerabilityAnalyzer:
    """
    Main analyzer for vulnerability score impact analysis.

    This is the primary interface for running comprehensive P/L impact
    analysis on completed backtests.

    Usage:
        analyzer = VulnerabilityAnalyzer(params)
        report = analyzer.analyze_backtest(trades, price_data)
        print(report.get_summary_text())
    """

    def __init__(self, params: Optional[VulnerabilityScoreParams] = None):
        """
        Initialize the analyzer.

        Args:
            params: Vulnerability score parameters. Uses defaults if None.
        """
        self.params = params or VulnerabilityScoreParams()
        self.scoring_engine = VulnerabilityScoringEngine(self.params)
        self.simulator = SwapSimulator(self.params)

    def update_params(self, params: VulnerabilityScoreParams) -> None:
        """Update analysis parameters."""
        self.params = params
        self.scoring_engine = VulnerabilityScoringEngine(params)
        self.simulator = SwapSimulator(params)

    def analyze_backtest(
        self,
        trades: List[Dict[str, Any]],
        price_data: Dict[str, pd.DataFrame],
        symbol: Optional[str] = None
    ) -> VulnerabilityAnalysisReport:
        """
        Run complete vulnerability analysis on backtest trades.

        Args:
            trades: List of trade dicts from backtest
            price_data: Dict mapping symbol to price DataFrame
            symbol: Symbol for the report (inferred from trades if None)

        Returns:
            VulnerabilityAnalysisReport with complete analysis

        Raises:
            FeatureError: If required price data is missing
            ValueError: If no trades provided
        """
        if not trades:
            raise ValueError("No trades provided for analysis")

        # Determine symbol
        if symbol is None:
            symbols = set(t['symbol'] for t in trades)
            symbol = list(symbols)[0] if len(symbols) == 1 else "PORTFOLIO"

        # Run simulation
        sim_result = self.simulator.run_simulation(trades, price_data)

        # Analyze each trade individually
        trade_analyses = []
        for trade in trades:
            analysis = self._analyze_single_trade(trade, price_data, sim_result)
            trade_analyses.append(analysis)

        # Calculate summary statistics
        total_trades = len(trades)
        trades_affected = sum(1 for t in trade_analyses if t.would_have_been_swapped)

        total_pl_natural = sum(t.pl_natural_dollars for t in trade_analyses)
        total_pl_vulnerability = sum(
            t.pl_if_exited_at_vulnerability_dollars if t.would_have_been_swapped else t.pl_natural_dollars
            for t in trade_analyses
        )
        total_pl_difference = total_pl_vulnerability - total_pl_natural
        total_pl_difference_pct = (total_pl_difference / abs(total_pl_natural) * 100) if total_pl_natural != 0 else 0

        # Categorize trades
        benefited = sum(1 for t in trade_analyses if t.would_have_been_swapped and t.pl_difference_pct > 0.5)
        hurt = sum(1 for t in trade_analyses if t.would_have_been_swapped and t.pl_difference_pct < -0.5)
        neutral = trades_affected - benefited - hurt

        # Quality metrics
        # False positive: swapped out a trade that was ultimately profitable
        false_positives = sum(
            1 for t in trade_analyses
            if t.would_have_been_swapped and t.pl_natural_pct > 0 and t.pl_if_exited_at_vulnerability_pct < t.pl_natural_pct
        )
        false_positive_rate = false_positives / trades_affected if trades_affected > 0 else 0

        # Accuracy: trades where the swap decision was correct
        correct_decisions = benefited + neutral
        accuracy = correct_decisions / trades_affected if trades_affected > 0 else 1.0

        # Timing metrics
        swapped_trades = [t for t in trade_analyses if t.would_have_been_swapped]
        avg_days_early = np.mean([t.days_before_vulnerability_exit for t in swapped_trades]) if swapped_trades else 0
        avg_pl_at_swap = np.mean([t.first_vulnerable_pl_pct for t in swapped_trades]) if swapped_trades else 0

        # Determine date range
        all_dates = []
        for t in trades:
            all_dates.append(t['entry_date'])
            all_dates.append(t['exit_date'])
        date_range = (min(all_dates), max(all_dates))

        return VulnerabilityAnalysisReport(
            symbol=symbol,
            date_range=date_range,
            parameter_set=self.params,
            trades=trade_analyses,
            total_trades=total_trades,
            trades_affected_by_vulnerability=trades_affected,
            total_pl_natural=total_pl_natural,
            total_pl_if_vulnerability=total_pl_vulnerability,
            total_pl_difference=total_pl_difference,
            total_pl_difference_pct=total_pl_difference_pct,
            benefited_count=benefited,
            hurt_count=hurt,
            neutral_count=neutral,
            false_positive_rate=false_positive_rate,
            accuracy=accuracy,
            avg_days_early_exit=avg_days_early,
            avg_pl_at_swap=avg_pl_at_swap
        )

    def _analyze_single_trade(
        self,
        trade: Dict[str, Any],
        price_data: Dict[str, pd.DataFrame],
        sim_result: SimulationResult
    ) -> TradeVulnerabilityAnalysis:
        """Analyze a single trade with vulnerability scoring."""
        trade_id = trade['trade_id']
        symbol = trade['symbol']

        entry_date = trade['entry_date']
        exit_date = trade['exit_date']
        entry_price = trade['entry_price']
        exit_price = trade['exit_price']
        pl_natural_pct = trade.get('pl_pct', 0.0)
        pl_natural_dollars = trade.get('pl', 0.0)
        quantity = trade.get('quantity', 1.0)

        # Normalize dates
        if isinstance(entry_date, pd.Timestamp):
            entry_date = entry_date.to_pydatetime()
        if isinstance(exit_date, pd.Timestamp):
            exit_date = exit_date.to_pydatetime()

        # Get daily timeline from simulation
        daily_timeline = sim_result.daily_scores.get(trade_id, [])

        # Check if this trade was swapped
        swap_event = next(
            (e for e in sim_result.swap_events if e.swapped_trade_id == trade_id),
            None
        )

        if swap_event:
            first_vulnerable_date = swap_event.date
            first_vulnerable_score = swap_event.vulnerability_score
            first_vulnerable_pl_pct = swap_event.pl_at_swap_pct
            days_before_exit = swap_event.days_early
            pl_at_vulnerability = swap_event.pl_at_swap_dollars
            pl_at_vulnerability_pct = swap_event.pl_at_swap_pct
            would_have_been_swapped = True
        else:
            # Find first vulnerable point from timeline (even if not swapped)
            first_vulnerable = None
            for record in daily_timeline:
                if record.would_be_swapped:
                    first_vulnerable = record
                    break

            if first_vulnerable:
                first_vulnerable_date = first_vulnerable.date
                first_vulnerable_score = first_vulnerable.vulnerability_score
                first_vulnerable_pl_pct = first_vulnerable.current_pl_pct
                if isinstance(first_vulnerable_date, datetime):
                    days_before_exit = (exit_date - first_vulnerable_date).days
                else:
                    days_before_exit = (exit_date.date() - first_vulnerable_date).days if hasattr(exit_date, 'date') else 0
                pl_at_vulnerability = (first_vulnerable.current_price - entry_price) * quantity
                pl_at_vulnerability_pct = first_vulnerable_pl_pct
                would_have_been_swapped = True
            else:
                first_vulnerable_date = None
                first_vulnerable_score = 100.0
                first_vulnerable_pl_pct = 0.0
                days_before_exit = 0
                pl_at_vulnerability = pl_natural_dollars
                pl_at_vulnerability_pct = pl_natural_pct
                would_have_been_swapped = False

        # Calculate P/L difference
        pl_difference_pct = pl_at_vulnerability_pct - pl_natural_pct
        pl_difference_dollars = pl_at_vulnerability - pl_natural_dollars

        # Determine benefit category
        was_loser = pl_natural_dollars < 0

        if not would_have_been_swapped:
            benefit_category = 'NOT_AFFECTED'
        elif abs(pl_difference_pct) < 0.5:
            benefit_category = 'NEUTRAL'
        elif was_loser and pl_at_vulnerability > pl_natural_dollars:
            benefit_category = 'AVOIDED_LOSS'
        elif pl_natural_pct > 5 and pl_at_vulnerability_pct < pl_natural_pct:
            benefit_category = 'KILLED_WINNER'
        elif pl_difference_pct > 0:
            benefit_category = 'IMPROVED_EXIT'
        else:
            benefit_category = 'PREMATURE_EXIT'

        return TradeVulnerabilityAnalysis(
            trade_id=trade_id,
            symbol=symbol,
            entry_date=entry_date,
            entry_price=entry_price,
            exit_date_natural=exit_date,
            exit_price_natural=exit_price,
            pl_natural_pct=pl_natural_pct,
            pl_natural_dollars=pl_natural_dollars,
            first_vulnerable_date=first_vulnerable_date,
            first_vulnerable_score=first_vulnerable_score,
            first_vulnerable_pl_pct=first_vulnerable_pl_pct,
            days_before_vulnerability_exit=days_before_exit,
            pl_if_exited_at_vulnerability_pct=pl_at_vulnerability_pct,
            pl_if_exited_at_vulnerability_dollars=pl_at_vulnerability,
            pl_difference_pct=pl_difference_pct,
            pl_difference_dollars=pl_difference_dollars,
            was_loser=was_loser,
            would_have_been_swapped=would_have_been_swapped,
            benefit_category=benefit_category,
            daily_timeline=daily_timeline
        )

    def compare_parameters(
        self,
        trades: List[Dict[str, Any]],
        price_data: Dict[str, pd.DataFrame],
        param_sets: List[VulnerabilityScoreParams]
    ) -> List[VulnerabilityAnalysisReport]:
        """
        Compare multiple parameter configurations.

        Useful for finding optimal parameters by running analysis
        with different settings.

        Args:
            trades: List of trade dicts
            price_data: Price data dict
            param_sets: List of parameter configurations to compare

        Returns:
            List of analysis reports, one per parameter set
        """
        reports = []

        for params in param_sets:
            self.update_params(params)
            report = self.analyze_backtest(trades, price_data)
            reports.append(report)

        return reports

    def find_optimal_parameters(
        self,
        trades: List[Dict[str, Any]],
        price_data: Dict[str, pd.DataFrame],
        immunity_range: Tuple[int, int] = (3, 14),
        threshold_range: Tuple[float, float] = (30, 70),
        step_immunity: int = 2,
        step_threshold: float = 10
    ) -> Tuple[VulnerabilityScoreParams, VulnerabilityAnalysisReport]:
        """
        Grid search for optimal vulnerability score parameters.

        Tests combinations of immunity_days and swap_threshold to find
        the configuration that maximizes P/L improvement.

        Args:
            trades: List of trade dicts
            price_data: Price data dict
            immunity_range: (min, max) range for immunity_days
            threshold_range: (min, max) range for swap_threshold
            step_immunity: Step size for immunity_days
            step_threshold: Step size for swap_threshold

        Returns:
            Tuple of (best_params, best_report)
        """
        best_params = None
        best_report = None
        best_pl_diff = float('-inf')

        for immunity in range(immunity_range[0], immunity_range[1] + 1, step_immunity):
            threshold = threshold_range[0]
            while threshold <= threshold_range[1]:
                # Create parameter set
                params = VulnerabilityScoreParams(
                    name=f"Grid_{immunity}d_{threshold:.0f}t",
                    immunity_days=immunity,
                    swap_threshold=threshold
                )

                try:
                    self.update_params(params)
                    report = self.analyze_backtest(trades, price_data)

                    # Optimize for P/L difference while maintaining reasonable accuracy
                    if report.accuracy >= 0.5 and report.total_pl_difference > best_pl_diff:
                        best_pl_diff = report.total_pl_difference
                        best_params = params
                        best_report = report

                except (FeatureError, ValueError):
                    pass

                threshold += step_threshold

        if best_params is None:
            # Return default if no good configuration found
            best_params = VulnerabilityScoreParams()
            self.update_params(best_params)
            best_report = self.analyze_backtest(trades, price_data)

        return best_params, best_report

    def generate_swap_event_log(
        self,
        trades: List[Dict[str, Any]],
        price_data: Dict[str, pd.DataFrame]
    ) -> pd.DataFrame:
        """
        Generate a detailed swap event log.

        Returns a DataFrame with all swap events and their details,
        suitable for export to CSV or display in a table.

        Args:
            trades: List of trade dicts
            price_data: Price data dict

        Returns:
            DataFrame with swap event details
        """
        sim_result = self.simulator.run_simulation(trades, price_data)

        if not sim_result.swap_events:
            return pd.DataFrame()

        rows = []
        for event in sim_result.swap_events:
            rows.append({
                'Date': event.date,
                'Symbol': event.swapped_symbol,
                'Score': event.vulnerability_score,
                'Reason': event.swap_reason,
                'Natural Exit': event.natural_exit_date,
                'Days Held': event.days_early + (event.natural_exit_date - event.date).days if hasattr(event.natural_exit_date, '__sub__') else 0,
                'Natural P/L': f"{event.natural_pl_pct:.2f}%",
                'Swapped P/L': f"{event.pl_at_swap_pct:.2f}%",
                'Difference': f"{event.pl_difference_pct:+.2f}%",
                'Outcome': event.outcome_category
            })

        return pd.DataFrame(rows)
