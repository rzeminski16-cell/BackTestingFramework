"""
P/L Impact Analysis and Reporting for Vulnerability Score Modeler.

This module analyzes the P/L impact of using vulnerability-based exits versus
natural strategy exits. It generates comprehensive reports with trade-by-trade
analysis and portfolio-level metrics.

Key Questions Answered:
- How much did I lose/gain from vulnerability-based exits?
- Which trades benefited vs. were hurt by the scoring function?
- What is the optimal parameter configuration?
"""

from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple, Callable
from enum import Enum
import json
from pathlib import Path
import pandas as pd
import numpy as np
import random

from .scoring import (
    VulnerabilityScoreParams,
    VulnerabilityScoringEngine,
    DailyVulnerabilityRecord
)
from .simulator import (
    SwapSimulator,
    SwapEvent,
    SimulationResult,
    SignalInjector
)
from .features import FeatureError


# ============================================================================
# OPTIMIZATION OBJECTIVES
# ============================================================================

class OptimizationObjective(Enum):
    """Pre-defined optimization objectives for parameter search."""
    MAXIMIZE_PL_DIFF = "maximize_pl_diff"  # Maximize P/L difference
    MAXIMIZE_ACCURACY = "maximize_accuracy"  # Maximize decision accuracy
    MINIMIZE_FALSE_POSITIVES = "minimize_false_positives"  # Minimize false positive rate
    MAXIMIZE_BENEFITED_RATIO = "maximize_benefited_ratio"  # Maximize benefited/hurt ratio
    BALANCED = "balanced"  # Balance P/L improvement with accuracy
    CONSERVATIVE = "conservative"  # Prioritize avoiding harm
    AGGRESSIVE = "aggressive"  # Prioritize capturing gains


@dataclass
class CustomObjective:
    """
    User-defined custom optimization objective.

    Allows full control over how "optimal" is defined by specifying
    weights for different metrics or a custom scoring function.

    Example usage:
        # Weight-based objective
        objective = CustomObjective(
            name="My Custom Objective",
            weights={
                'pl_diff_weight': 0.4,
                'accuracy_weight': 0.3,
                'benefited_ratio_weight': 0.2,
                'false_positive_penalty': 0.1
            }
        )

        # Function-based objective
        def my_scorer(report):
            return report.total_pl_difference * report.accuracy

        objective = CustomObjective(
            name="Custom Function",
            scoring_function=my_scorer
        )
    """
    name: str
    description: str = ""

    # Weight-based scoring (sum of weighted metrics)
    weights: Dict[str, float] = field(default_factory=dict)

    # Available weight keys:
    # - pl_diff_weight: Weight for total P/L difference (normalized)
    # - accuracy_weight: Weight for decision accuracy
    # - benefited_ratio_weight: Weight for benefited/hurt ratio
    # - false_positive_penalty: Penalty for false positive rate
    # - trades_affected_weight: Weight for % of trades affected
    # - avg_days_early_weight: Weight for average days early exit

    # Custom scoring function (overrides weights if provided)
    # Should take a VulnerabilityAnalysisReport and return a float score
    scoring_function: Optional[Callable[['VulnerabilityAnalysisReport'], float]] = None

    # Constraints (optional)
    min_accuracy: float = 0.0  # Minimum acceptable accuracy
    max_false_positive_rate: float = 1.0  # Maximum acceptable FP rate
    min_trades_affected_pct: float = 0.0  # Minimum % of trades to affect
    max_trades_affected_pct: float = 1.0  # Maximum % of trades to affect


def get_objective_scorer(
    objective: OptimizationObjective | CustomObjective
) -> Callable[['VulnerabilityAnalysisReport'], Tuple[float, bool]]:
    """
    Get a scoring function for the given objective.

    Args:
        objective: Optimization objective

    Returns:
        Function that takes a report and returns (score, passes_constraints)
    """
    if isinstance(objective, CustomObjective):
        return _custom_objective_scorer(objective)

    # Pre-defined objectives
    scorers = {
        OptimizationObjective.MAXIMIZE_PL_DIFF: _pl_diff_scorer,
        OptimizationObjective.MAXIMIZE_ACCURACY: _accuracy_scorer,
        OptimizationObjective.MINIMIZE_FALSE_POSITIVES: _fp_scorer,
        OptimizationObjective.MAXIMIZE_BENEFITED_RATIO: _benefited_ratio_scorer,
        OptimizationObjective.BALANCED: _balanced_scorer,
        OptimizationObjective.CONSERVATIVE: _conservative_scorer,
        OptimizationObjective.AGGRESSIVE: _aggressive_scorer,
    }

    return scorers.get(objective, _balanced_scorer)


def _pl_diff_scorer(report: 'VulnerabilityAnalysisReport') -> Tuple[float, bool]:
    """Maximize P/L difference."""
    passes = report.accuracy >= 0.4  # Basic constraint
    return report.total_pl_difference, passes


def _accuracy_scorer(report: 'VulnerabilityAnalysisReport') -> Tuple[float, bool]:
    """Maximize decision accuracy."""
    passes = report.trades_affected_by_vulnerability > 0
    return report.accuracy * 100, passes


def _fp_scorer(report: 'VulnerabilityAnalysisReport') -> Tuple[float, bool]:
    """Minimize false positive rate (negate for maximization)."""
    passes = report.trades_affected_by_vulnerability > 0
    return -report.false_positive_rate * 100, passes


def _benefited_ratio_scorer(report: 'VulnerabilityAnalysisReport') -> Tuple[float, bool]:
    """Maximize benefited/hurt ratio."""
    passes = report.trades_affected_by_vulnerability > 0
    if report.hurt_count == 0:
        ratio = report.benefited_count * 10  # High score if no hurt trades
    else:
        ratio = report.benefited_count / report.hurt_count
    return ratio, passes


def _balanced_scorer(report: 'VulnerabilityAnalysisReport') -> Tuple[float, bool]:
    """Balance P/L improvement with accuracy."""
    passes = report.accuracy >= 0.5 and report.trades_affected_by_vulnerability > 0

    # Normalize P/L diff to a reasonable scale
    pl_score = min(max(report.total_pl_difference / 1000, -10), 10)
    accuracy_score = report.accuracy * 10

    return pl_score + accuracy_score, passes


def _conservative_scorer(report: 'VulnerabilityAnalysisReport') -> Tuple[float, bool]:
    """Prioritize avoiding harm to trades."""
    passes = (
        report.false_positive_rate <= 0.3 and
        report.hurt_count <= report.benefited_count
    )

    # Heavily penalize false positives
    score = report.total_pl_difference - (report.false_positive_rate * 1000)
    score += report.benefited_count * 10 - report.hurt_count * 20

    return score, passes


def _aggressive_scorer(report: 'VulnerabilityAnalysisReport') -> Tuple[float, bool]:
    """Prioritize capturing gains, even at cost of some losers."""
    passes = report.trades_affected_by_vulnerability >= report.total_trades * 0.1

    # Focus on total P/L, but still consider win rate
    score = report.total_pl_difference * 2
    score += (report.benefited_count - report.hurt_count) * 5

    return score, passes


def _custom_objective_scorer(
    objective: CustomObjective
) -> Callable[['VulnerabilityAnalysisReport'], Tuple[float, bool]]:
    """Create scorer for custom objective."""

    def scorer(report: 'VulnerabilityAnalysisReport') -> Tuple[float, bool]:
        # Check constraints
        passes = True
        if report.accuracy < objective.min_accuracy:
            passes = False
        if report.false_positive_rate > objective.max_false_positive_rate:
            passes = False

        affected_pct = report.trades_affected_by_vulnerability / report.total_trades if report.total_trades > 0 else 0
        if affected_pct < objective.min_trades_affected_pct:
            passes = False
        if affected_pct > objective.max_trades_affected_pct:
            passes = False

        # Calculate score
        if objective.scoring_function is not None:
            return objective.scoring_function(report), passes

        # Weight-based scoring
        weights = objective.weights
        score = 0.0

        # P/L difference (normalized to ~1-100 range)
        if 'pl_diff_weight' in weights:
            pl_normalized = report.total_pl_difference / 100  # Assuming ~$10k typical
            score += weights['pl_diff_weight'] * pl_normalized

        # Accuracy (0-1 range, multiply by 100)
        if 'accuracy_weight' in weights:
            score += weights['accuracy_weight'] * report.accuracy * 100

        # Benefited ratio
        if 'benefited_ratio_weight' in weights:
            if report.hurt_count == 0:
                ratio = report.benefited_count * 10
            else:
                ratio = report.benefited_count / report.hurt_count
            score += weights['benefited_ratio_weight'] * ratio * 10

        # False positive penalty
        if 'false_positive_penalty' in weights:
            score -= weights['false_positive_penalty'] * report.false_positive_rate * 100

        # Trades affected
        if 'trades_affected_weight' in weights:
            score += weights['trades_affected_weight'] * affected_pct * 100

        # Days early exit (could be good or bad depending on strategy)
        if 'avg_days_early_weight' in weights:
            score += weights['avg_days_early_weight'] * report.avg_days_early_exit

        return score, passes

    return scorer


# Pre-built custom objectives for convenience
OBJECTIVE_PRESETS = {
    'max_pl': CustomObjective(
        name="Maximum P/L Improvement",
        description="Optimize purely for P/L improvement with minimal constraints",
        weights={'pl_diff_weight': 1.0},
        min_accuracy=0.4
    ),
    'balanced': CustomObjective(
        name="Balanced",
        description="Balance P/L improvement with decision accuracy",
        weights={'pl_diff_weight': 0.5, 'accuracy_weight': 0.3, 'false_positive_penalty': 0.2},
        min_accuracy=0.5
    ),
    'conservative': CustomObjective(
        name="Conservative",
        description="Prioritize avoiding harm to good trades",
        weights={'accuracy_weight': 0.4, 'false_positive_penalty': 0.4, 'pl_diff_weight': 0.2},
        min_accuracy=0.6,
        max_false_positive_rate=0.3
    ),
    'aggressive': CustomObjective(
        name="Aggressive",
        description="Maximize trades affected while maintaining positive P/L",
        weights={'trades_affected_weight': 0.4, 'pl_diff_weight': 0.4, 'benefited_ratio_weight': 0.2},
        min_trades_affected_pct=0.2
    ),
    'low_false_positive': CustomObjective(
        name="Low False Positive",
        description="Minimize false positives above all else",
        weights={'false_positive_penalty': 0.6, 'accuracy_weight': 0.3, 'pl_diff_weight': 0.1},
        max_false_positive_rate=0.2
    ),
}


@dataclass
class TradeVulnerabilityAnalysis:
    """
    Complete vulnerability analysis for a single trade.

    Contains all metrics needed to understand how vulnerability scoring
    would have affected this specific trade.
    """
    trade_id: str
    symbol: str
    entry_date: datetime
    entry_price: float

    # Natural exit (from backtest)
    exit_date_natural: datetime
    exit_price_natural: float
    pl_natural_pct: float
    pl_natural_dollars: float

    # Vulnerability analysis
    first_vulnerable_date: Optional[datetime]
    first_vulnerable_score: float
    first_vulnerable_pl_pct: float
    days_before_vulnerability_exit: int

    # Counterfactual (if we had used vulnerability scoring)
    pl_if_exited_at_vulnerability_pct: float
    pl_if_exited_at_vulnerability_dollars: float
    pl_difference_pct: float
    pl_difference_dollars: float

    # Quality metrics
    was_loser: bool  # Natural exit was a loss
    would_have_been_swapped: bool
    benefit_category: str  # 'AVOIDED_LOSS', 'KILLED_WINNER', 'NEUTRAL', 'IMPROVED_EXIT'

    # Daily timeline (for charting)
    daily_timeline: List[DailyVulnerabilityRecord] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for export."""
        return {
            'trade_id': self.trade_id,
            'symbol': self.symbol,
            'entry_date': self.entry_date.strftime('%Y-%m-%d') if hasattr(self.entry_date, 'strftime') else str(self.entry_date),
            'entry_price': self.entry_price,
            'exit_date_natural': self.exit_date_natural.strftime('%Y-%m-%d') if hasattr(self.exit_date_natural, 'strftime') else str(self.exit_date_natural),
            'exit_price_natural': self.exit_price_natural,
            'pl_natural_pct': self.pl_natural_pct,
            'pl_natural_dollars': self.pl_natural_dollars,
            'first_vulnerable_date': self.first_vulnerable_date.strftime('%Y-%m-%d') if self.first_vulnerable_date and hasattr(self.first_vulnerable_date, 'strftime') else None,
            'first_vulnerable_score': self.first_vulnerable_score,
            'first_vulnerable_pl_pct': self.first_vulnerable_pl_pct,
            'days_before_vulnerability_exit': self.days_before_vulnerability_exit,
            'pl_if_exited_at_vulnerability_pct': self.pl_if_exited_at_vulnerability_pct,
            'pl_if_exited_at_vulnerability_dollars': self.pl_if_exited_at_vulnerability_dollars,
            'pl_difference_pct': self.pl_difference_pct,
            'pl_difference_dollars': self.pl_difference_dollars,
            'was_loser': self.was_loser,
            'would_have_been_swapped': self.would_have_been_swapped,
            'benefit_category': self.benefit_category
        }


@dataclass
class VulnerabilityAnalysisReport:
    """
    Complete analysis report for a backtest with vulnerability scoring.

    Contains portfolio-level metrics, trade-by-trade analysis, and
    all data needed for visualization and reporting.
    """
    symbol: str
    date_range: Tuple[datetime, datetime]
    parameter_set: VulnerabilityScoreParams

    # Trade-level analysis
    trades: List[TradeVulnerabilityAnalysis]

    # Summary statistics
    total_trades: int
    trades_affected_by_vulnerability: int

    # P/L Analysis
    total_pl_natural: float
    total_pl_if_vulnerability: float
    total_pl_difference: float
    total_pl_difference_pct: float

    # Trade Categorization
    benefited_count: int  # Trades where vulnerability score was better
    hurt_count: int  # Trades where vulnerability score was worse
    neutral_count: int  # Negligible difference

    # Quality Metrics
    false_positive_rate: float  # % of trades closed but would have recovered
    accuracy: float  # % of trades where vulnerability decision was good

    # Timing metrics
    avg_days_early_exit: float
    avg_pl_at_swap: float

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for export."""
        return {
            'symbol': self.symbol,
            'date_range': [
                self.date_range[0].strftime('%Y-%m-%d') if hasattr(self.date_range[0], 'strftime') else str(self.date_range[0]),
                self.date_range[1].strftime('%Y-%m-%d') if hasattr(self.date_range[1], 'strftime') else str(self.date_range[1])
            ],
            'parameter_set': self.parameter_set.to_dict(),
            'trades': [t.to_dict() for t in self.trades],
            'total_trades': self.total_trades,
            'trades_affected_by_vulnerability': self.trades_affected_by_vulnerability,
            'total_pl_natural': self.total_pl_natural,
            'total_pl_if_vulnerability': self.total_pl_if_vulnerability,
            'total_pl_difference': self.total_pl_difference,
            'total_pl_difference_pct': self.total_pl_difference_pct,
            'benefited_count': self.benefited_count,
            'hurt_count': self.hurt_count,
            'neutral_count': self.neutral_count,
            'false_positive_rate': self.false_positive_rate,
            'accuracy': self.accuracy,
            'avg_days_early_exit': self.avg_days_early_exit,
            'avg_pl_at_swap': self.avg_pl_at_swap
        }

    def to_json(self, filepath: Path) -> None:
        """Save report to JSON file."""
        with open(filepath, 'w') as f:
            json.dump(self.to_dict(), f, indent=2, default=str)

    def to_csv(self, filepath: Path) -> None:
        """Save trade analysis to CSV file."""
        trade_dicts = [t.to_dict() for t in self.trades]
        df = pd.DataFrame(trade_dicts)
        df.to_csv(filepath, index=False)

    def get_summary_text(self) -> str:
        """Get human-readable summary text."""
        lines = [
            f"Vulnerability Score Analysis Report",
            f"=" * 50,
            f"Symbol: {self.symbol}",
            f"Date Range: {self.date_range[0]} to {self.date_range[1]}",
            f"Parameters: {self.parameter_set.name}",
            f"",
            f"--- TRADE SUMMARY ---",
            f"Total Trades: {self.total_trades}",
            f"Trades Affected: {self.trades_affected_by_vulnerability} ({self.trades_affected_by_vulnerability/self.total_trades*100:.1f}%)" if self.total_trades > 0 else "Trades Affected: 0",
            f"",
            f"--- P/L IMPACT ---",
            f"Natural Total P/L: ${self.total_pl_natural:,.2f}",
            f"Vulnerability Total P/L: ${self.total_pl_if_vulnerability:,.2f}",
            f"Difference: ${self.total_pl_difference:,.2f} ({self.total_pl_difference_pct:+.2f}%)",
            f"",
            f"--- TRADE CATEGORIZATION ---",
            f"Benefited: {self.benefited_count}",
            f"Hurt: {self.hurt_count}",
            f"Neutral: {self.neutral_count}",
            f"",
            f"--- QUALITY METRICS ---",
            f"False Positive Rate: {self.false_positive_rate*100:.1f}%",
            f"Accuracy: {self.accuracy*100:.1f}%",
            f"",
            f"--- TIMING ---",
            f"Avg Days Early Exit: {self.avg_days_early_exit:.1f}",
            f"Avg P/L at Swap: {self.avg_pl_at_swap:.2f}%",
        ]
        return "\n".join(lines)

    def get_key_insight(self) -> str:
        """Generate a key insight based on the analysis."""
        if self.trades_affected_by_vulnerability == 0:
            return "No trades would have been affected by vulnerability scoring with current parameters."

        if self.total_pl_difference > 0:
            return f"Vulnerability scoring would have IMPROVED returns by ${self.total_pl_difference:,.2f}. " \
                   f"Consider enabling it with these parameters."

        if self.hurt_count > self.benefited_count:
            return f"Vulnerability scoring is too aggressive - closing {self.hurt_count} winners too early. " \
                   f"Consider increasing swap threshold or reducing decay rate."

        if self.false_positive_rate > 0.4:
            return f"High false positive rate ({self.false_positive_rate*100:.0f}%). " \
                   f"Many trades would be closed but would have recovered. Increase immunity period."

        return f"Vulnerability scoring shows mixed results. " \
               f"P/L difference: ${self.total_pl_difference:,.2f}."

    def get_recommendation(self) -> str:
        """Generate a recommendation based on the analysis."""
        if self.total_pl_difference > 0 and self.accuracy > 0.6:
            return "RECOMMEND: Enable vulnerability scoring with current parameters."

        if self.false_positive_rate > 0.5:
            return f"ADJUST: Increase immunity_days from {self.parameter_set.immunity_days} to {self.parameter_set.immunity_days + 5}"

        if self.hurt_count > self.benefited_count * 2:
            return f"ADJUST: Increase swap_threshold from {self.parameter_set.swap_threshold} to {min(90, self.parameter_set.swap_threshold + 20)}"

        if self.trades_affected_by_vulnerability < self.total_trades * 0.1:
            return f"ADJUST: Parameters are too conservative. Reduce immunity_days or increase weights."

        return "CONTINUE: Run additional simulations with different parameters to find optimal configuration."


class VulnerabilityAnalyzer:
    """
    Main analyzer for vulnerability score impact analysis.

    This is the primary interface for running comprehensive P/L impact
    analysis on completed backtests.

    Usage:
        analyzer = VulnerabilityAnalyzer(params)
        report = analyzer.analyze_backtest(trades, price_data)
        print(report.get_summary_text())
    """

    def __init__(self, params: Optional[VulnerabilityScoreParams] = None):
        """
        Initialize the analyzer.

        Args:
            params: Vulnerability score parameters. Uses defaults if None.
        """
        self.params = params or VulnerabilityScoreParams()
        self.scoring_engine = VulnerabilityScoringEngine(self.params)
        self.simulator = SwapSimulator(self.params)

    def update_params(self, params: VulnerabilityScoreParams) -> None:
        """Update analysis parameters."""
        self.params = params
        self.scoring_engine = VulnerabilityScoringEngine(params)
        self.simulator = SwapSimulator(params)

    def analyze_backtest(
        self,
        trades: List[Dict[str, Any]],
        price_data: Dict[str, pd.DataFrame],
        symbol: Optional[str] = None
    ) -> VulnerabilityAnalysisReport:
        """
        Run complete vulnerability analysis on backtest trades.

        Args:
            trades: List of trade dicts from backtest
            price_data: Dict mapping symbol to price DataFrame
            symbol: Symbol for the report (inferred from trades if None)

        Returns:
            VulnerabilityAnalysisReport with complete analysis

        Raises:
            FeatureError: If required price data is missing
            ValueError: If no trades provided
        """
        if not trades:
            raise ValueError("No trades provided for analysis")

        # Determine symbol
        if symbol is None:
            symbols = set(t['symbol'] for t in trades)
            symbol = list(symbols)[0] if len(symbols) == 1 else "PORTFOLIO"

        # Run simulation
        sim_result = self.simulator.run_simulation(trades, price_data)

        # Analyze each trade individually
        trade_analyses = []
        for trade in trades:
            analysis = self._analyze_single_trade(trade, price_data, sim_result)
            trade_analyses.append(analysis)

        # Calculate summary statistics
        total_trades = len(trades)
        trades_affected = sum(1 for t in trade_analyses if t.would_have_been_swapped)

        total_pl_natural = sum(t.pl_natural_dollars for t in trade_analyses)
        total_pl_vulnerability = sum(
            t.pl_if_exited_at_vulnerability_dollars if t.would_have_been_swapped else t.pl_natural_dollars
            for t in trade_analyses
        )
        total_pl_difference = total_pl_vulnerability - total_pl_natural
        total_pl_difference_pct = (total_pl_difference / abs(total_pl_natural) * 100) if total_pl_natural != 0 else 0

        # Categorize trades
        benefited = sum(1 for t in trade_analyses if t.would_have_been_swapped and t.pl_difference_pct > 0.5)
        hurt = sum(1 for t in trade_analyses if t.would_have_been_swapped and t.pl_difference_pct < -0.5)
        neutral = trades_affected - benefited - hurt

        # Quality metrics
        # False positive: swapped out a trade that was ultimately profitable
        false_positives = sum(
            1 for t in trade_analyses
            if t.would_have_been_swapped and t.pl_natural_pct > 0 and t.pl_if_exited_at_vulnerability_pct < t.pl_natural_pct
        )
        false_positive_rate = false_positives / trades_affected if trades_affected > 0 else 0

        # Accuracy: trades where the swap decision was correct
        correct_decisions = benefited + neutral
        accuracy = correct_decisions / trades_affected if trades_affected > 0 else 1.0

        # Timing metrics
        swapped_trades = [t for t in trade_analyses if t.would_have_been_swapped]
        avg_days_early = np.mean([t.days_before_vulnerability_exit for t in swapped_trades]) if swapped_trades else 0
        avg_pl_at_swap = np.mean([t.first_vulnerable_pl_pct for t in swapped_trades]) if swapped_trades else 0

        # Determine date range
        all_dates = []
        for t in trades:
            all_dates.append(t['entry_date'])
            all_dates.append(t['exit_date'])
        date_range = (min(all_dates), max(all_dates))

        return VulnerabilityAnalysisReport(
            symbol=symbol,
            date_range=date_range,
            parameter_set=self.params,
            trades=trade_analyses,
            total_trades=total_trades,
            trades_affected_by_vulnerability=trades_affected,
            total_pl_natural=total_pl_natural,
            total_pl_if_vulnerability=total_pl_vulnerability,
            total_pl_difference=total_pl_difference,
            total_pl_difference_pct=total_pl_difference_pct,
            benefited_count=benefited,
            hurt_count=hurt,
            neutral_count=neutral,
            false_positive_rate=false_positive_rate,
            accuracy=accuracy,
            avg_days_early_exit=avg_days_early,
            avg_pl_at_swap=avg_pl_at_swap
        )

    def _analyze_single_trade(
        self,
        trade: Dict[str, Any],
        price_data: Dict[str, pd.DataFrame],
        sim_result: SimulationResult
    ) -> TradeVulnerabilityAnalysis:
        """Analyze a single trade with vulnerability scoring."""
        trade_id = trade['trade_id']
        symbol = trade['symbol']

        entry_date = trade['entry_date']
        exit_date = trade['exit_date']
        entry_price = trade['entry_price']
        exit_price = trade['exit_price']
        pl_natural_pct = trade.get('pl_pct', 0.0)
        pl_natural_dollars = trade.get('pl', 0.0)
        quantity = trade.get('quantity', 1.0)

        # Normalize dates
        if isinstance(entry_date, pd.Timestamp):
            entry_date = entry_date.to_pydatetime()
        if isinstance(exit_date, pd.Timestamp):
            exit_date = exit_date.to_pydatetime()

        # Get daily timeline from simulation
        daily_timeline = sim_result.daily_scores.get(trade_id, [])

        # Check if this trade was swapped
        swap_event = next(
            (e for e in sim_result.swap_events if e.swapped_trade_id == trade_id),
            None
        )

        if swap_event:
            first_vulnerable_date = swap_event.date
            first_vulnerable_score = swap_event.vulnerability_score
            first_vulnerable_pl_pct = swap_event.pl_at_swap_pct
            days_before_exit = swap_event.days_early
            pl_at_vulnerability = swap_event.pl_at_swap_dollars
            pl_at_vulnerability_pct = swap_event.pl_at_swap_pct
            would_have_been_swapped = True
        else:
            # Find first vulnerable point from timeline (even if not swapped)
            first_vulnerable = None
            for record in daily_timeline:
                if record.would_be_swapped:
                    first_vulnerable = record
                    break

            if first_vulnerable:
                first_vulnerable_date = first_vulnerable.date
                first_vulnerable_score = first_vulnerable.vulnerability_score
                first_vulnerable_pl_pct = first_vulnerable.current_pl_pct
                if isinstance(first_vulnerable_date, datetime):
                    days_before_exit = (exit_date - first_vulnerable_date).days
                else:
                    days_before_exit = (exit_date.date() - first_vulnerable_date).days if hasattr(exit_date, 'date') else 0
                pl_at_vulnerability = (first_vulnerable.current_price - entry_price) * quantity
                pl_at_vulnerability_pct = first_vulnerable_pl_pct
                would_have_been_swapped = True
            else:
                first_vulnerable_date = None
                first_vulnerable_score = 100.0
                first_vulnerable_pl_pct = 0.0
                days_before_exit = 0
                pl_at_vulnerability = pl_natural_dollars
                pl_at_vulnerability_pct = pl_natural_pct
                would_have_been_swapped = False

        # Calculate P/L difference
        pl_difference_pct = pl_at_vulnerability_pct - pl_natural_pct
        pl_difference_dollars = pl_at_vulnerability - pl_natural_dollars

        # Determine benefit category
        was_loser = pl_natural_dollars < 0

        if not would_have_been_swapped:
            benefit_category = 'NOT_AFFECTED'
        elif abs(pl_difference_pct) < 0.5:
            benefit_category = 'NEUTRAL'
        elif was_loser and pl_at_vulnerability > pl_natural_dollars:
            benefit_category = 'AVOIDED_LOSS'
        elif pl_natural_pct > 5 and pl_at_vulnerability_pct < pl_natural_pct:
            benefit_category = 'KILLED_WINNER'
        elif pl_difference_pct > 0:
            benefit_category = 'IMPROVED_EXIT'
        else:
            benefit_category = 'PREMATURE_EXIT'

        return TradeVulnerabilityAnalysis(
            trade_id=trade_id,
            symbol=symbol,
            entry_date=entry_date,
            entry_price=entry_price,
            exit_date_natural=exit_date,
            exit_price_natural=exit_price,
            pl_natural_pct=pl_natural_pct,
            pl_natural_dollars=pl_natural_dollars,
            first_vulnerable_date=first_vulnerable_date,
            first_vulnerable_score=first_vulnerable_score,
            first_vulnerable_pl_pct=first_vulnerable_pl_pct,
            days_before_vulnerability_exit=days_before_exit,
            pl_if_exited_at_vulnerability_pct=pl_at_vulnerability_pct,
            pl_if_exited_at_vulnerability_dollars=pl_at_vulnerability,
            pl_difference_pct=pl_difference_pct,
            pl_difference_dollars=pl_difference_dollars,
            was_loser=was_loser,
            would_have_been_swapped=would_have_been_swapped,
            benefit_category=benefit_category,
            daily_timeline=daily_timeline
        )

    def compare_parameters(
        self,
        trades: List[Dict[str, Any]],
        price_data: Dict[str, pd.DataFrame],
        param_sets: List[VulnerabilityScoreParams]
    ) -> List[VulnerabilityAnalysisReport]:
        """
        Compare multiple parameter configurations.

        Useful for finding optimal parameters by running analysis
        with different settings.

        Args:
            trades: List of trade dicts
            price_data: Price data dict
            param_sets: List of parameter configurations to compare

        Returns:
            List of analysis reports, one per parameter set
        """
        reports = []

        for params in param_sets:
            self.update_params(params)
            report = self.analyze_backtest(trades, price_data)
            reports.append(report)

        return reports

    def find_optimal_parameters(
        self,
        trades: List[Dict[str, Any]],
        price_data: Dict[str, pd.DataFrame],
        immunity_range: Tuple[int, int] = (3, 14),
        threshold_range: Tuple[float, float] = (30, 70),
        step_immunity: int = 2,
        step_threshold: float = 10,
        objective: OptimizationObjective | CustomObjective = OptimizationObjective.BALANCED,
        decay_rate_range: Optional[Tuple[float, float]] = None,
        step_decay_rate: float = 0.5
    ) -> Tuple[VulnerabilityScoreParams, VulnerabilityAnalysisReport, Dict[str, Any]]:
        """
        Grid search for optimal vulnerability score parameters.

        Tests combinations of parameters to find the configuration that
        best meets the specified optimization objective.

        Args:
            trades: List of trade dicts
            price_data: Price data dict
            immunity_range: (min, max) range for immunity_days
            threshold_range: (min, max) range for swap_threshold
            step_immunity: Step size for immunity_days
            step_threshold: Step size for swap_threshold
            objective: What to optimize for (enum or custom objective)
            decay_rate_range: Optional (min, max) range for decay_rate
            step_decay_rate: Step size for decay_rate

        Returns:
            Tuple of (best_params, best_report, optimization_details)
            optimization_details contains:
                - all_results: List of (params, report, score) tuples
                - search_space_size: Number of configurations tested
                - objective_name: Name of objective used
        """
        scorer = get_objective_scorer(objective)

        best_params = None
        best_report = None
        best_score = float('-inf')
        all_results = []

        # Build decay rate range
        if decay_rate_range is None:
            decay_rates = [2.0]  # Just use default
        else:
            decay_rates = []
            dr = decay_rate_range[0]
            while dr <= decay_rate_range[1]:
                decay_rates.append(dr)
                dr += step_decay_rate

        # Grid search
        for immunity in range(immunity_range[0], immunity_range[1] + 1, step_immunity):
            threshold = threshold_range[0]
            while threshold <= threshold_range[1]:
                for decay_rate in decay_rates:
                    # Create parameter set
                    params = VulnerabilityScoreParams(
                        name=f"Grid_{immunity}d_{threshold:.0f}t_{decay_rate:.1f}dr",
                        immunity_days=immunity,
                        swap_threshold=threshold,
                        decay_rate=decay_rate
                    )

                    try:
                        self.update_params(params)
                        report = self.analyze_backtest(trades, price_data)

                        # Score using the objective
                        score, passes_constraints = scorer(report)
                        all_results.append({
                            'params': params,
                            'report': report,
                            'score': score,
                            'passes_constraints': passes_constraints
                        })

                        # Update best if this passes constraints and has better score
                        if passes_constraints and score > best_score:
                            best_score = score
                            best_params = params
                            best_report = report

                    except (FeatureError, ValueError):
                        pass

                threshold += step_threshold

        if best_params is None:
            # Try to find best result even if none pass constraints
            valid_results = [r for r in all_results if r['report'] is not None]
            if valid_results:
                best_result = max(valid_results, key=lambda r: r['score'])
                best_params = best_result['params']
                best_report = best_result['report']
            else:
                # Return default if no valid results
                best_params = VulnerabilityScoreParams()
                self.update_params(best_params)
                best_report = self.analyze_backtest(trades, price_data)

        # Get objective name
        if isinstance(objective, OptimizationObjective):
            objective_name = objective.value
        else:
            objective_name = objective.name

        optimization_details = {
            'all_results': all_results,
            'search_space_size': len(all_results),
            'objective_name': objective_name,
            'best_score': best_score
        }

        return best_params, best_report, optimization_details

    def generate_swap_event_log(
        self,
        trades: List[Dict[str, Any]],
        price_data: Dict[str, pd.DataFrame]
    ) -> pd.DataFrame:
        """
        Generate a detailed swap event log.

        Returns a DataFrame with all swap events and their details,
        suitable for export to CSV or display in a table.

        Args:
            trades: List of trade dicts
            price_data: Price data dict

        Returns:
            DataFrame with swap event details
        """
        sim_result = self.simulator.run_simulation(trades, price_data)

        if not sim_result.swap_events:
            return pd.DataFrame()

        rows = []
        for event in sim_result.swap_events:
            rows.append({
                'Date': event.date,
                'Symbol': event.swapped_symbol,
                'Score': event.vulnerability_score,
                'Reason': event.swap_reason,
                'Natural Exit': event.natural_exit_date,
                'Days Held': event.days_early + (event.natural_exit_date - event.date).days if hasattr(event.natural_exit_date, '__sub__') else 0,
                'Natural P/L': f"{event.natural_pl_pct:.2f}%",
                'Swapped P/L': f"{event.pl_at_swap_pct:.2f}%",
                'Difference': f"{event.pl_difference_pct:+.2f}%",
                'Outcome': event.outcome_category
            })

        return pd.DataFrame(rows)

    # =========================================================================
    # ADVANCED ANALYSIS FEATURES
    # =========================================================================

    def run_sensitivity_analysis(
        self,
        trades: List[Dict[str, Any]],
        price_data: Dict[str, pd.DataFrame],
        base_params: Optional[VulnerabilityScoreParams] = None,
        param_name: str = 'immunity_days',
        param_range: Optional[List[Any]] = None,
        metric: str = 'total_pl_difference'
    ) -> Dict[str, Any]:
        """
        Run sensitivity analysis on a single parameter.

        Shows how changes to one parameter affect the specified metric
        while holding all other parameters constant.

        Args:
            trades: List of trade dicts
            price_data: Price data dict
            base_params: Base parameters (uses current if None)
            param_name: Parameter to vary ('immunity_days', 'swap_threshold', 'decay_rate')
            param_range: List of values to test (auto-generated if None)
            metric: Metric to track ('total_pl_difference', 'accuracy', 'false_positive_rate', etc.)

        Returns:
            Dict with:
                - param_values: List of tested values
                - metric_values: Corresponding metric values
                - best_value: Value that maximizes/minimizes metric
                - sensitivity_score: How sensitive metric is to this parameter
        """
        if base_params is None:
            base_params = self.params

        # Generate default ranges if not provided
        if param_range is None:
            if param_name == 'immunity_days':
                param_range = list(range(1, 21))
            elif param_name == 'swap_threshold':
                param_range = [i * 5 for i in range(1, 20)]
            elif param_name == 'decay_rate':
                param_range = [i * 0.5 for i in range(1, 11)]
            else:
                raise ValueError(f"Unknown parameter: {param_name}")

        results = []

        for value in param_range:
            # Create modified params
            params_dict = base_params.to_dict()
            params_dict[param_name] = value
            params_dict['name'] = f"Sensitivity_{param_name}_{value}"

            try:
                test_params = VulnerabilityScoreParams.from_dict(params_dict)
                self.update_params(test_params)
                report = self.analyze_backtest(trades, price_data)

                # Extract metric
                metric_value = getattr(report, metric, None)
                if metric_value is not None:
                    results.append({
                        'param_value': value,
                        'metric_value': metric_value,
                        'report': report
                    })
            except (FeatureError, ValueError):
                continue

        if not results:
            return {'error': 'No valid results'}

        param_values = [r['param_value'] for r in results]
        metric_values = [r['metric_value'] for r in results]

        # Find best value (maximize for P/L, accuracy; minimize for FP rate)
        minimize_metrics = ['false_positive_rate', 'hurt_count']
        if metric in minimize_metrics:
            best_idx = metric_values.index(min(metric_values))
        else:
            best_idx = metric_values.index(max(metric_values))

        # Calculate sensitivity score (normalized standard deviation)
        if len(metric_values) > 1:
            metric_mean = np.mean(metric_values)
            metric_std = np.std(metric_values)
            sensitivity_score = metric_std / abs(metric_mean) if metric_mean != 0 else 0
        else:
            sensitivity_score = 0

        return {
            'param_name': param_name,
            'param_values': param_values,
            'metric_name': metric,
            'metric_values': metric_values,
            'best_value': param_values[best_idx],
            'best_metric': metric_values[best_idx],
            'sensitivity_score': sensitivity_score,
            'results': results
        }

    def run_walk_forward_validation(
        self,
        trades: List[Dict[str, Any]],
        price_data: Dict[str, pd.DataFrame],
        n_folds: int = 5,
        optimization_objective: OptimizationObjective | CustomObjective = OptimizationObjective.BALANCED,
        train_ratio: float = 0.7
    ) -> Dict[str, Any]:
        """
        Run walk-forward validation to test parameter robustness.

        Splits data into sequential folds, optimizes on training portion,
        and validates on out-of-sample portion.

        Args:
            trades: List of trade dicts
            price_data: Price data dict
            n_folds: Number of walk-forward folds
            optimization_objective: Objective for optimization
            train_ratio: Ratio of each fold used for training (default 0.7)

        Returns:
            Dict with:
                - fold_results: List of per-fold results
                - overall_metrics: Aggregated out-of-sample metrics
                - parameter_stability: How much optimal params vary across folds
        """
        if len(trades) < n_folds * 5:
            raise ValueError(f"Need at least {n_folds * 5} trades for {n_folds}-fold validation")

        # Sort trades by entry date
        sorted_trades = sorted(trades, key=lambda t: t['entry_date'])
        trades_per_fold = len(sorted_trades) // n_folds

        fold_results = []
        optimal_params_list = []

        for fold in range(n_folds):
            # Define fold boundaries
            fold_start = fold * trades_per_fold
            fold_end = (fold + 1) * trades_per_fold if fold < n_folds - 1 else len(sorted_trades)
            fold_trades = sorted_trades[fold_start:fold_end]

            # Split into train/test
            train_size = int(len(fold_trades) * train_ratio)
            train_trades = fold_trades[:train_size]
            test_trades = fold_trades[train_size:]

            if len(train_trades) < 3 or len(test_trades) < 2:
                continue

            try:
                # Optimize on training set
                best_params, train_report, _ = self.find_optimal_parameters(
                    train_trades,
                    price_data,
                    objective=optimization_objective
                )
                optimal_params_list.append(best_params)

                # Validate on test set
                self.update_params(best_params)
                test_report = self.analyze_backtest(test_trades, price_data)

                fold_results.append({
                    'fold': fold + 1,
                    'train_trades': len(train_trades),
                    'test_trades': len(test_trades),
                    'optimal_params': best_params.to_dict(),
                    'train_pl_diff': train_report.total_pl_difference,
                    'test_pl_diff': test_report.total_pl_difference,
                    'train_accuracy': train_report.accuracy,
                    'test_accuracy': test_report.accuracy,
                    'is_overfitting': test_report.total_pl_difference < train_report.total_pl_difference * 0.5
                })

            except (FeatureError, ValueError) as e:
                fold_results.append({
                    'fold': fold + 1,
                    'error': str(e)
                })

        # Calculate overall metrics
        valid_folds = [f for f in fold_results if 'error' not in f]

        if valid_folds:
            avg_test_pl = np.mean([f['test_pl_diff'] for f in valid_folds])
            avg_test_accuracy = np.mean([f['test_accuracy'] for f in valid_folds])
            overfitting_rate = sum(1 for f in valid_folds if f.get('is_overfitting', False)) / len(valid_folds)

            # Parameter stability
            if len(optimal_params_list) > 1:
                immunity_days_std = np.std([p.immunity_days for p in optimal_params_list])
                threshold_std = np.std([p.swap_threshold for p in optimal_params_list])
                param_stability = 1 - min(1, (immunity_days_std / 10 + threshold_std / 50) / 2)
            else:
                param_stability = 1.0
        else:
            avg_test_pl = 0
            avg_test_accuracy = 0
            overfitting_rate = 0
            param_stability = 0

        return {
            'n_folds': n_folds,
            'fold_results': fold_results,
            'overall_metrics': {
                'avg_out_of_sample_pl': avg_test_pl,
                'avg_out_of_sample_accuracy': avg_test_accuracy,
                'overfitting_rate': overfitting_rate
            },
            'parameter_stability': param_stability,
            'recommendation': self._get_validation_recommendation(avg_test_pl, overfitting_rate, param_stability)
        }

    def _get_validation_recommendation(
        self,
        avg_pl: float,
        overfitting_rate: float,
        stability: float
    ) -> str:
        """Generate recommendation based on validation results."""
        if stability < 0.5:
            return "CAUTION: Parameters are unstable across folds. Consider using more conservative settings."
        if overfitting_rate > 0.5:
            return "WARNING: High overfitting rate detected. Reduce model complexity or use simpler features."
        if avg_pl > 0 and stability > 0.7:
            return "GOOD: Parameters appear robust with positive out-of-sample performance."
        if avg_pl <= 0:
            return "NEUTRAL: Out-of-sample performance is mixed. Consider different optimization objective."
        return "OK: Results are acceptable but could be improved."

    def calculate_feature_importance(
        self,
        trades: List[Dict[str, Any]],
        price_data: Dict[str, pd.DataFrame],
        method: str = 'permutation'
    ) -> Dict[str, Any]:
        """
        Calculate importance ranking for each feature.

        Shows which features contribute most to the final P/L impact.

        Args:
            trades: List of trade dicts
            price_data: Price data dict
            method: 'permutation' (shuffle feature) or 'ablation' (disable feature)

        Returns:
            Dict with:
                - feature_importance: Dict of feature_name -> importance_score
                - ranking: Sorted list of (feature_name, score) tuples
                - baseline_pl: P/L with all features enabled
        """
        # Get baseline result
        baseline_report = self.analyze_backtest(trades, price_data)
        baseline_pl = baseline_report.total_pl_difference

        feature_scores = {}
        original_params = self.params

        for feature_name in self.params.get_enabled_features():
            if method == 'ablation':
                # Disable this feature and re-run
                params_dict = original_params.to_dict()
                params_dict['features'][feature_name]['enabled'] = False
                params_dict['name'] = f"Ablation_{feature_name}"

                try:
                    test_params = VulnerabilityScoreParams.from_dict(params_dict)
                    self.update_params(test_params)
                    report = self.analyze_backtest(trades, price_data)

                    # Importance = how much P/L drops when feature is removed
                    importance = baseline_pl - report.total_pl_difference
                    feature_scores[feature_name] = importance

                except (FeatureError, ValueError):
                    feature_scores[feature_name] = 0

            elif method == 'permutation':
                # Not directly applicable to this context, use contribution-based
                # Sum up weighted contributions from each trade's analysis
                total_contribution = 0
                for trade_analysis in baseline_report.trades:
                    for record in trade_analysis.daily_timeline:
                        contribution = record.feature_contributions.get(feature_name, 0)
                        total_contribution += abs(contribution)

                feature_scores[feature_name] = total_contribution

        # Restore original params
        self.update_params(original_params)

        # Normalize scores
        max_score = max(feature_scores.values()) if feature_scores else 1
        if max_score > 0:
            normalized_scores = {k: v / max_score * 100 for k, v in feature_scores.items()}
        else:
            normalized_scores = feature_scores

        # Create ranking
        ranking = sorted(normalized_scores.items(), key=lambda x: x[1], reverse=True)

        return {
            'feature_importance': normalized_scores,
            'ranking': ranking,
            'baseline_pl': baseline_pl,
            'method': method,
            'most_important': ranking[0][0] if ranking else None,
            'least_important': ranking[-1][0] if ranking else None
        }

    def run_monte_carlo_analysis(
        self,
        trades: List[Dict[str, Any]],
        price_data: Dict[str, pd.DataFrame],
        n_simulations: int = 1000,
        confidence_levels: List[float] = [0.05, 0.25, 0.50, 0.75, 0.95]
    ) -> Dict[str, Any]:
        """
        Run Monte Carlo simulation to estimate confidence intervals.

        Randomly samples trades with replacement and calculates
        distribution of possible outcomes.

        Args:
            trades: List of trade dicts
            price_data: Price data dict
            n_simulations: Number of Monte Carlo iterations
            confidence_levels: Quantiles to calculate

        Returns:
            Dict with:
                - pl_distribution: List of simulated P/L differences
                - confidence_intervals: Dict of level -> P/L value
                - statistics: Mean, std, min, max of distribution
                - probability_positive: Chance of positive P/L impact
        """
        if len(trades) < 5:
            raise ValueError("Need at least 5 trades for Monte Carlo analysis")

        pl_distribution = []

        for _ in range(n_simulations):
            # Sample trades with replacement
            sampled_indices = [random.randint(0, len(trades) - 1) for _ in range(len(trades))]
            sampled_trades = [trades[i].copy() for i in sampled_indices]

            # Assign new trade IDs to avoid conflicts
            for idx, trade in enumerate(sampled_trades):
                trade['trade_id'] = f"MC_{idx}_{trade['trade_id']}"

            try:
                report = self.analyze_backtest(sampled_trades, price_data)
                pl_distribution.append(report.total_pl_difference)
            except (FeatureError, ValueError):
                continue

        if not pl_distribution:
            return {'error': 'No successful simulations'}

        # Calculate statistics
        pl_array = np.array(pl_distribution)
        confidence_intervals = {}

        for level in confidence_levels:
            confidence_intervals[f"{int(level * 100)}%"] = float(np.percentile(pl_array, level * 100))

        return {
            'n_simulations': len(pl_distribution),
            'pl_distribution': pl_distribution,
            'confidence_intervals': confidence_intervals,
            'statistics': {
                'mean': float(np.mean(pl_array)),
                'std': float(np.std(pl_array)),
                'min': float(np.min(pl_array)),
                'max': float(np.max(pl_array)),
                'median': float(np.median(pl_array))
            },
            'probability_positive': float(np.sum(pl_array > 0) / len(pl_array)),
            'probability_significant_gain': float(np.sum(pl_array > 100) / len(pl_array)),
            'probability_significant_loss': float(np.sum(pl_array < -100) / len(pl_array))
        }

    def run_trade_grouping_analysis(
        self,
        trades: List[Dict[str, Any]],
        price_data: Dict[str, pd.DataFrame],
        grouping_criteria: str = 'symbol'
    ) -> Dict[str, Any]:
        """
        Analyze vulnerability score impact by trade groups.

        Groups trades by specified criteria and analyzes each group separately.

        Args:
            trades: List of trade dicts
            price_data: Price data dict
            grouping_criteria: How to group trades:
                - 'symbol': By security symbol
                - 'month': By entry month
                - 'quarter': By entry quarter
                - 'year': By entry year
                - 'duration': By trade duration (short/medium/long)
                - 'pl_bucket': By natural P/L range

        Returns:
            Dict with:
                - groups: Dict of group_name -> analysis_report
                - summary: Comparison of metrics across groups
                - best_group: Group with highest P/L improvement
                - worst_group: Group with lowest P/L improvement
        """
        # Group trades
        groups = {}

        for trade in trades:
            if grouping_criteria == 'symbol':
                group_key = trade['symbol']

            elif grouping_criteria == 'month':
                entry = trade['entry_date']
                group_key = entry.strftime('%Y-%m') if hasattr(entry, 'strftime') else str(entry)[:7]

            elif grouping_criteria == 'quarter':
                entry = trade['entry_date']
                if hasattr(entry, 'quarter'):
                    group_key = f"{entry.year}-Q{entry.quarter}"
                else:
                    month = entry.month if hasattr(entry, 'month') else int(str(entry)[5:7])
                    quarter = (month - 1) // 3 + 1
                    year = entry.year if hasattr(entry, 'year') else str(entry)[:4]
                    group_key = f"{year}-Q{quarter}"

            elif grouping_criteria == 'year':
                entry = trade['entry_date']
                group_key = str(entry.year) if hasattr(entry, 'year') else str(entry)[:4]

            elif grouping_criteria == 'duration':
                entry = trade['entry_date']
                exit_d = trade['exit_date']
                if hasattr(entry, 'date'):
                    days = (exit_d - entry).days
                else:
                    days = 7  # Default
                if days <= 5:
                    group_key = 'Short (1-5 days)'
                elif days <= 20:
                    group_key = 'Medium (6-20 days)'
                else:
                    group_key = 'Long (21+ days)'

            elif grouping_criteria == 'pl_bucket':
                pl_pct = trade.get('pl_pct', 0)
                if pl_pct < -10:
                    group_key = 'Big Loss (<-10%)'
                elif pl_pct < 0:
                    group_key = 'Small Loss (-10% to 0%)'
                elif pl_pct < 10:
                    group_key = 'Small Win (0% to 10%)'
                else:
                    group_key = 'Big Win (>10%)'

            else:
                raise ValueError(f"Unknown grouping criteria: {grouping_criteria}")

            if group_key not in groups:
                groups[group_key] = []
            groups[group_key].append(trade)

        # Analyze each group
        group_reports = {}
        group_summaries = []

        for group_name, group_trades in groups.items():
            if len(group_trades) < 2:
                continue

            try:
                report = self.analyze_backtest(group_trades, price_data)
                group_reports[group_name] = report

                group_summaries.append({
                    'group': group_name,
                    'n_trades': report.total_trades,
                    'pl_difference': report.total_pl_difference,
                    'accuracy': report.accuracy,
                    'benefited': report.benefited_count,
                    'hurt': report.hurt_count,
                    'false_positive_rate': report.false_positive_rate
                })

            except (FeatureError, ValueError) as e:
                group_summaries.append({
                    'group': group_name,
                    'error': str(e)
                })

        # Find best and worst groups
        valid_summaries = [s for s in group_summaries if 'error' not in s]

        if valid_summaries:
            best_group = max(valid_summaries, key=lambda x: x['pl_difference'])
            worst_group = min(valid_summaries, key=lambda x: x['pl_difference'])
        else:
            best_group = None
            worst_group = None

        return {
            'grouping_criteria': grouping_criteria,
            'n_groups': len(groups),
            'group_reports': group_reports,
            'summary': pd.DataFrame(group_summaries).to_dict('records') if group_summaries else [],
            'best_group': best_group,
            'worst_group': worst_group,
            'recommendation': self._get_grouping_recommendation(valid_summaries)
        }

    def _get_grouping_recommendation(self, summaries: List[Dict]) -> str:
        """Generate recommendation based on grouping analysis."""
        if not summaries:
            return "Insufficient data for grouping analysis."

        # Check if vulnerability scoring works better for certain groups
        positive_groups = [s for s in summaries if s['pl_difference'] > 0]
        negative_groups = [s for s in summaries if s['pl_difference'] < 0]

        if len(positive_groups) == len(summaries):
            return "Vulnerability scoring improves P/L across all groups. Consider enabling it globally."

        if len(negative_groups) == len(summaries):
            return "Vulnerability scoring hurts P/L across all groups. Consider different parameters or disabling."

        positive_names = [s['group'] for s in positive_groups]
        negative_names = [s['group'] for s in negative_groups]

        return (
            f"Mixed results: Scoring helps with [{', '.join(positive_names[:3])}] "
            f"but hurts [{', '.join(negative_names[:3])}]. "
            f"Consider applying selectively."
        )
