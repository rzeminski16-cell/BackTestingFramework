"""
Data Loader for Vulnerability Score Modeler.

This module handles loading backtest results and enriching them with
raw CSV price data for vulnerability analysis.

Key Responsibilities:
- Load completed backtest trade logs (CSV/JSON)
- Load raw price data from CSV files
- Validate that required columns exist
- Enrich trades with daily price data for feature calculation
- Provide clear error messages when data is missing
"""

from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import json
import pandas as pd

from .features import FeatureError, AVAILABLE_FEATURES


@dataclass
class EnrichedTrade:
    """
    A trade enriched with daily price data for vulnerability analysis.

    Contains all the information needed to calculate vulnerability scores
    for every day of the trade's lifetime.
    """
    # Basic trade info
    trade_id: str
    symbol: str
    entry_date: datetime
    entry_price: float
    exit_date: datetime
    exit_price: float
    quantity: float
    side: str

    # P/L info
    pl: float  # Dollars
    pl_pct: float  # Percentage
    exit_reason: str

    # Daily price data during trade lifetime
    daily_closes: Dict[datetime, float] = field(default_factory=dict)
    daily_highs: Dict[datetime, float] = field(default_factory=dict)
    daily_lows: Dict[datetime, float] = field(default_factory=dict)
    daily_volumes: Dict[datetime, float] = field(default_factory=dict)

    # Metadata
    duration_days: int = 0
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for simulation."""
        return {
            'trade_id': self.trade_id,
            'symbol': self.symbol,
            'entry_date': self.entry_date,
            'entry_price': self.entry_price,
            'exit_date': self.exit_date,
            'exit_price': self.exit_price,
            'quantity': self.quantity,
            'pl': self.pl,
            'pl_pct': self.pl_pct,
            'exit_reason': self.exit_reason
        }


class DataAvailabilityReport:
    """Report on data availability for vulnerability analysis."""

    def __init__(self):
        self.symbols_available: List[str] = []
        self.symbols_missing: List[str] = []
        self.column_issues: Dict[str, List[str]] = {}  # symbol -> missing columns
        self.date_range_issues: Dict[str, str] = {}  # symbol -> issue description
        self.warnings: List[str] = []
        self.errors: List[str] = []

    @property
    def is_valid(self) -> bool:
        """Check if data is valid for analysis."""
        return len(self.errors) == 0 and len(self.symbols_missing) == 0

    def get_summary(self) -> str:
        """Get human-readable summary."""
        lines = ["Data Availability Report", "=" * 40]

        if self.symbols_available:
            lines.append(f"Symbols Available: {', '.join(self.symbols_available)}")

        if self.symbols_missing:
            lines.append(f"Symbols Missing: {', '.join(self.symbols_missing)}")

        if self.column_issues:
            lines.append("\nColumn Issues:")
            for symbol, cols in self.column_issues.items():
                lines.append(f"  {symbol}: Missing {', '.join(cols)}")

        if self.date_range_issues:
            lines.append("\nDate Range Issues:")
            for symbol, issue in self.date_range_issues.items():
                lines.append(f"  {symbol}: {issue}")

        if self.warnings:
            lines.append("\nWarnings:")
            for w in self.warnings:
                lines.append(f"  - {w}")

        if self.errors:
            lines.append("\nErrors:")
            for e in self.errors:
                lines.append(f"  - {e}")

        return "\n".join(lines)


class BacktestTradeLoader:
    """
    Loads backtest trades and enriches them with price data.

    This is the main interface for loading data into the vulnerability
    score modeler.

    Usage:
        loader = BacktestTradeLoader(data_directory=Path('raw_data'))
        trades, price_data, report = loader.load_from_trade_log(
            trade_log_path=Path('logs/backtest/trades.csv')
        )

        if report.is_valid:
            analyzer = VulnerabilityAnalyzer()
            result = analyzer.analyze_backtest(trades, price_data)
    """

    # Required columns in price data
    REQUIRED_COLUMNS = ['date', 'close']
    OPTIONAL_COLUMNS = ['high', 'low', 'open', 'volume']

    def __init__(
        self,
        data_directory: Path,
        date_column: str = 'date',
        close_column: str = 'close'
    ):
        """
        Initialize the trade loader.

        Args:
            data_directory: Path to directory containing raw CSV price data
            date_column: Name of date column in CSV files (will check 'date' and 'time')
            close_column: Name of close price column
        """
        self.data_directory = Path(data_directory)
        self.date_column = date_column
        self.close_column = close_column

        if not self.data_directory.exists():
            raise FileNotFoundError(f"Data directory not found: {data_directory}")

    def load_from_trade_log(
        self,
        trade_log_path: Path,
        symbol_override: Optional[str] = None
    ) -> Tuple[List[Dict[str, Any]], Dict[str, pd.DataFrame], DataAvailabilityReport]:
        """
        Load trades from a trade log CSV file and enrich with price data.

        Args:
            trade_log_path: Path to trade log CSV file
            symbol_override: Override symbol for all trades (for single-security logs)

        Returns:
            Tuple of (trades_list, price_data_dict, availability_report)

        Raises:
            FileNotFoundError: If trade log file not found
            FeatureError: If critical data is missing
        """
        report = DataAvailabilityReport()

        # Load trade log
        if not trade_log_path.exists():
            raise FileNotFoundError(f"Trade log not found: {trade_log_path}")

        trade_df = pd.read_csv(trade_log_path)
        trade_df.columns = trade_df.columns.str.lower().str.strip()

        # Validate trade log columns
        required_trade_cols = ['entry_date', 'entry_price', 'exit_date', 'exit_price']
        missing_cols = [c for c in required_trade_cols if c not in trade_df.columns]
        if missing_cols:
            raise FeatureError(
                'trade_log',
                f"Trade log missing required columns",
                missing_cols
            )

        # Get unique symbols
        if symbol_override:
            symbols = [symbol_override]
            trade_df['symbol'] = symbol_override
        elif 'symbol' in trade_df.columns:
            symbols = trade_df['symbol'].unique().tolist()
        else:
            # Try to infer from filename
            filename = trade_log_path.stem
            parts = filename.split('_')
            if len(parts) >= 2:
                symbol_override = parts[-2].upper()  # e.g., "strategy_AAPL_trades.csv"
                symbols = [symbol_override]
                trade_df['symbol'] = symbol_override
            else:
                raise FeatureError(
                    'trade_log',
                    "Trade log must have 'symbol' column or symbol in filename",
                    ['symbol']
                )

        # Load price data for all symbols
        price_data = {}
        for symbol in symbols:
            try:
                df = self._load_price_data(symbol)
                price_data[symbol] = df
                report.symbols_available.append(symbol)

                # Check for optional columns
                missing_optional = [c for c in self.OPTIONAL_COLUMNS if c not in df.columns]
                if missing_optional:
                    report.warnings.append(
                        f"{symbol}: Missing optional columns {missing_optional}. "
                        f"Some features may not be available."
                    )

            except FileNotFoundError:
                report.symbols_missing.append(symbol)
                report.errors.append(f"Price data file not found for {symbol}")

            except FeatureError as e:
                report.column_issues[symbol] = e.missing_data
                report.errors.append(str(e))

        # If critical symbols missing, raise error
        if report.symbols_missing:
            raise FeatureError(
                'price_data',
                f"Missing price data for symbols: {report.symbols_missing}",
                report.symbols_missing
            )

        # Convert trade log to list of dicts
        trades = self._convert_trade_df(trade_df)

        # Validate date ranges
        for trade in trades:
            symbol = trade['symbol']
            if symbol in price_data:
                df = price_data[symbol]
                entry_date = trade['entry_date']
                exit_date = trade['exit_date']

                # Check if price data covers trade period
                data_start = df['date'].min()
                data_end = df['date'].max()

                if entry_date < data_start:
                    report.date_range_issues[symbol] = (
                        f"Trade entry {entry_date} is before price data start {data_start}"
                    )
                    report.warnings.append(
                        f"{symbol}: Trade entry before available price data"
                    )

                if exit_date > data_end:
                    report.date_range_issues[symbol] = (
                        f"Trade exit {exit_date} is after price data end {data_end}"
                    )
                    report.warnings.append(
                        f"{symbol}: Trade exit after available price data"
                    )

        return trades, price_data, report

    def load_from_backtest_result(
        self,
        result_path: Path
    ) -> Tuple[List[Dict[str, Any]], Dict[str, pd.DataFrame], DataAvailabilityReport]:
        """
        Load trades from a BacktestResult JSON file.

        Args:
            result_path: Path to backtest result JSON file

        Returns:
            Tuple of (trades_list, price_data_dict, availability_report)
        """
        report = DataAvailabilityReport()

        if not result_path.exists():
            raise FileNotFoundError(f"Backtest result not found: {result_path}")

        with open(result_path, 'r') as f:
            result_data = json.load(f)

        # Extract trades
        trades_data = result_data.get('trades', [])
        symbol = result_data.get('symbol', 'UNKNOWN')

        if not trades_data:
            raise FeatureError(
                'backtest_result',
                "No trades found in backtest result",
                ['trades']
            )

        # Convert to standard format
        trades = []
        for t in trades_data:
            trade = {
                'trade_id': t.get('trade_id', f"T{len(trades)+1:06d}"),
                'symbol': t.get('symbol', symbol),
                'entry_date': pd.to_datetime(t['entry_date']),
                'entry_price': float(t['entry_price']),
                'exit_date': pd.to_datetime(t['exit_date']),
                'exit_price': float(t['exit_price']),
                'quantity': float(t.get('quantity', 1.0)),
                'pl': float(t.get('pl', 0.0)),
                'pl_pct': float(t.get('pl_pct', 0.0)),
                'exit_reason': t.get('exit_reason', 'UNKNOWN')
            }
            trades.append(trade)

        # Load price data
        symbols = list(set(t['symbol'] for t in trades))
        price_data = {}

        for sym in symbols:
            try:
                df = self._load_price_data(sym)
                price_data[sym] = df
                report.symbols_available.append(sym)
            except (FileNotFoundError, FeatureError) as e:
                report.symbols_missing.append(sym)
                report.errors.append(str(e))

        if report.symbols_missing:
            raise FeatureError(
                'price_data',
                f"Missing price data for symbols: {report.symbols_missing}",
                report.symbols_missing
            )

        return trades, price_data, report

    def load_price_data_for_symbols(
        self,
        symbols: List[str]
    ) -> Tuple[Dict[str, pd.DataFrame], DataAvailabilityReport]:
        """
        Load price data for multiple symbols.

        Args:
            symbols: List of symbol names

        Returns:
            Tuple of (price_data_dict, availability_report)
        """
        report = DataAvailabilityReport()
        price_data = {}

        for symbol in symbols:
            try:
                df = self._load_price_data(symbol)
                price_data[symbol] = df
                report.symbols_available.append(symbol)

                # Check for features that won't be available
                missing_for_features = self._check_feature_availability(df)
                if missing_for_features:
                    report.warnings.append(
                        f"{symbol}: The following features will not be available "
                        f"due to missing columns: {missing_for_features}"
                    )

            except FileNotFoundError:
                report.symbols_missing.append(symbol)
                report.errors.append(f"Price data file not found for {symbol}")

            except FeatureError as e:
                report.column_issues[symbol] = e.missing_data
                report.errors.append(str(e))

        return price_data, report

    def _load_price_data(self, symbol: str) -> pd.DataFrame:
        """
        Load and validate price data for a symbol.

        Args:
            symbol: Symbol name

        Returns:
            DataFrame with price data

        Raises:
            FileNotFoundError: If CSV file not found
            FeatureError: If required columns missing
        """
        # Try different file patterns
        possible_paths = [
            self.data_directory / f"{symbol}.csv",
            self.data_directory / f"{symbol.upper()}.csv",
            self.data_directory / f"{symbol.lower()}.csv",
        ]

        file_path = None
        for path in possible_paths:
            if path.exists():
                file_path = path
                break

        if file_path is None:
            raise FileNotFoundError(
                f"Price data file not found for {symbol}. "
                f"Searched: {[str(p) for p in possible_paths]}"
            )

        # Load CSV
        df = pd.read_csv(file_path)

        # Normalize column names
        df.columns = df.columns.str.lower().str.strip()

        # Handle date column (might be 'time' instead of 'date')
        if 'date' not in df.columns and 'time' in df.columns:
            df.rename(columns={'time': 'date'}, inplace=True)

        # Validate required columns
        missing = [c for c in self.REQUIRED_COLUMNS if c not in df.columns]
        if missing:
            raise FeatureError(
                f'price_data_{symbol}',
                f"Price data for {symbol} missing required columns",
                missing
            )

        # Parse date column
        df['date'] = pd.to_datetime(df['date'], format='mixed', dayfirst=True)
        df.sort_values('date', inplace=True)
        df.reset_index(drop=True, inplace=True)

        return df

    def _convert_trade_df(self, df: pd.DataFrame) -> List[Dict[str, Any]]:
        """Convert trade DataFrame to list of dicts."""
        trades = []

        for _, row in df.iterrows():
            # Generate trade_id if not present
            if 'trade_id' in row and pd.notna(row['trade_id']):
                trade_id = str(row['trade_id'])
            else:
                trade_id = f"T{len(trades)+1:06d}"

            trade = {
                'trade_id': trade_id,
                'symbol': row.get('symbol', 'UNKNOWN'),
                'entry_date': pd.to_datetime(row['entry_date']),
                'entry_price': float(row['entry_price']),
                'exit_date': pd.to_datetime(row['exit_date']),
                'exit_price': float(row['exit_price']),
                'quantity': float(row.get('quantity', 1.0)),
                'pl': float(row.get('pl', 0.0)),
                'pl_pct': float(row.get('pl_pct', 0.0)),
                'exit_reason': row.get('exit_reason', 'UNKNOWN')
            }
            trades.append(trade)

        return trades

    def _check_feature_availability(self, df: pd.DataFrame) -> List[str]:
        """Check which features won't be available due to missing columns."""
        unavailable_features = []

        for feature_name, definition in AVAILABLE_FEATURES.items():
            missing = [c for c in definition.required_columns if c not in df.columns]
            if missing:
                unavailable_features.append(feature_name)

        return unavailable_features

    def enrich_trades(
        self,
        trades: List[Dict[str, Any]],
        price_data: Dict[str, pd.DataFrame]
    ) -> List[EnrichedTrade]:
        """
        Enrich trades with daily price data.

        Args:
            trades: List of trade dicts
            price_data: Dict mapping symbol to price DataFrame

        Returns:
            List of EnrichedTrade objects with daily price data
        """
        enriched = []

        for trade in trades:
            symbol = trade['symbol']
            entry_date = trade['entry_date']
            exit_date = trade['exit_date']

            if symbol not in price_data:
                raise FeatureError(
                    'enrich_trades',
                    f"No price data for symbol {symbol}",
                    [symbol]
                )

            df = price_data[symbol]

            # Filter to trade period
            mask = (df['date'] >= entry_date) & (df['date'] <= exit_date)
            trade_period = df[mask]

            # Extract daily data
            daily_closes = {row['date']: row['close'] for _, row in trade_period.iterrows()}
            daily_highs = {}
            daily_lows = {}
            daily_volumes = {}

            if 'high' in trade_period.columns:
                daily_highs = {row['date']: row['high'] for _, row in trade_period.iterrows()}
            if 'low' in trade_period.columns:
                daily_lows = {row['date']: row['low'] for _, row in trade_period.iterrows()}
            if 'volume' in trade_period.columns:
                daily_volumes = {row['date']: row['volume'] for _, row in trade_period.iterrows()}

            enriched_trade = EnrichedTrade(
                trade_id=trade['trade_id'],
                symbol=symbol,
                entry_date=entry_date,
                entry_price=trade['entry_price'],
                exit_date=exit_date,
                exit_price=trade['exit_price'],
                quantity=trade.get('quantity', 1.0),
                side=trade.get('side', 'LONG'),
                pl=trade.get('pl', 0.0),
                pl_pct=trade.get('pl_pct', 0.0),
                exit_reason=trade.get('exit_reason', 'UNKNOWN'),
                daily_closes=daily_closes,
                daily_highs=daily_highs,
                daily_lows=daily_lows,
                daily_volumes=daily_volumes,
                duration_days=len(trade_period)
            )
            enriched.append(enriched_trade)

        return enriched

    def get_available_symbols(self) -> List[str]:
        """Get list of symbols with available price data."""
        csv_files = list(self.data_directory.glob("*.csv"))
        return sorted([f.stem for f in csv_files])

    def load_multiple_trade_logs(
        self,
        trade_log_paths: List[Path],
        backtest_labels: Optional[List[str]] = None
    ) -> Tuple[List[Dict[str, Any]], Dict[str, pd.DataFrame], DataAvailabilityReport]:
        """
        Load trades from multiple trade log files and combine them.

        Each trade is tagged with its source backtest for identification.

        Args:
            trade_log_paths: List of paths to trade log CSV files
            backtest_labels: Optional labels for each backtest (defaults to filenames)

        Returns:
            Tuple of (combined_trades_list, price_data_dict, availability_report)
        """
        if not trade_log_paths:
            raise ValueError("No trade log paths provided")

        # Generate labels if not provided
        if backtest_labels is None:
            backtest_labels = [p.stem for p in trade_log_paths]

        if len(backtest_labels) != len(trade_log_paths):
            raise ValueError("Number of labels must match number of trade logs")

        combined_report = DataAvailabilityReport()
        all_trades = []
        combined_price_data: Dict[str, pd.DataFrame] = {}
        trade_counter = 0

        for path, label in zip(trade_log_paths, backtest_labels):
            try:
                trades, price_data, report = self.load_from_trade_log(path)

                # Tag each trade with source backtest
                for trade in trades:
                    trade_counter += 1
                    trade['backtest_source'] = label
                    trade['original_trade_id'] = trade['trade_id']
                    trade['trade_id'] = f"{label}_{trade['trade_id']}"

                all_trades.extend(trades)

                # Merge price data (use first occurrence for each symbol)
                for symbol, df in price_data.items():
                    if symbol not in combined_price_data:
                        combined_price_data[symbol] = df

                # Merge report
                combined_report.symbols_available.extend(
                    [s for s in report.symbols_available if s not in combined_report.symbols_available]
                )
                combined_report.symbols_missing.extend(report.symbols_missing)
                combined_report.warnings.extend([f"[{label}] {w}" for w in report.warnings])
                combined_report.errors.extend([f"[{label}] {e}" for e in report.errors])

            except Exception as e:
                combined_report.errors.append(f"[{label}] Failed to load: {str(e)}")

        if not all_trades:
            raise FeatureError(
                'multi_load',
                "No trades loaded from any of the provided files",
                [str(p) for p in trade_log_paths]
            )

        return all_trades, combined_price_data, combined_report

    def load_portfolio_backtest_directory(
        self,
        portfolio_dir: Path
    ) -> Tuple[List[Dict[str, Any]], Dict[str, pd.DataFrame], DataAvailabilityReport]:
        """
        Load all trades from a portfolio backtest directory.

        Looks for:
        - portfolio_trades.csv (consolidated trades)
        - *_trades.csv in base directory (new structure)
        - trades/*.csv (legacy structure)

        Args:
            portfolio_dir: Path to portfolio backtest directory

        Returns:
            Tuple of (trades_list, price_data_dict, availability_report)
        """
        report = DataAvailabilityReport()

        if not portfolio_dir.exists():
            raise FileNotFoundError(f"Portfolio directory not found: {portfolio_dir}")

        # Try consolidated file first
        consolidated_path = portfolio_dir / "portfolio_trades.csv"
        if consolidated_path.exists():
            return self.load_from_trade_log(consolidated_path)

        # Check for individual trade files in base directory (new structure)
        trade_files = [f for f in portfolio_dir.glob("*_trades.csv")
                      if f.name != "portfolio_trades.csv"]
        if trade_files:
            return self.load_multiple_trade_logs(trade_files)

        # Fallback: check legacy trades/ subdirectory
        trades_dir = portfolio_dir / "trades"
        if trades_dir.exists():
            trade_files = list(trades_dir.glob("*_trades.csv"))
            if trade_files:
                return self.load_multiple_trade_logs(trade_files)

        raise FeatureError(
            'portfolio_load',
            f"No trade files found in {portfolio_dir}",
            ['portfolio_trades.csv', '*_trades.csv']
        )

    def validate_data_for_analysis(
        self,
        trades: List[Dict[str, Any]],
        price_data: Dict[str, pd.DataFrame],
        enabled_features: List[str]
    ) -> DataAvailabilityReport:
        """
        Validate that all data needed for analysis is available.

        Args:
            trades: List of trade dicts
            price_data: Dict of price DataFrames
            enabled_features: List of feature names that will be used

        Returns:
            DataAvailabilityReport with validation results
        """
        report = DataAvailabilityReport()

        # Check each trade
        for trade in trades:
            symbol = trade['symbol']

            if symbol not in price_data:
                if symbol not in report.symbols_missing:
                    report.symbols_missing.append(symbol)
                    report.errors.append(f"No price data for {symbol}")
                continue

            df = price_data[symbol]

            # Check required columns for each enabled feature
            for feature_name in enabled_features:
                if feature_name not in AVAILABLE_FEATURES:
                    continue

                definition = AVAILABLE_FEATURES[feature_name]
                missing = [c for c in definition.required_columns if c not in df.columns]

                if missing:
                    if symbol not in report.column_issues:
                        report.column_issues[symbol] = []
                    report.column_issues[symbol].extend(missing)
                    report.errors.append(
                        f"Feature '{feature_name}' requires columns {missing} "
                        f"which are missing from {symbol} price data"
                    )

            # Check date coverage
            entry_date = pd.to_datetime(trade['entry_date'])
            exit_date = pd.to_datetime(trade['exit_date'])
            data_start = df['date'].min()
            data_end = df['date'].max()

            if entry_date < data_start or exit_date > data_end:
                report.date_range_issues[symbol] = (
                    f"Trade period ({entry_date} to {exit_date}) "
                    f"not fully covered by data ({data_start} to {data_end})"
                )
                report.warnings.append(
                    f"{symbol}: Incomplete price data for trade period"
                )

            if symbol not in report.symbols_available and symbol not in report.symbols_missing:
                report.symbols_available.append(symbol)

        return report
